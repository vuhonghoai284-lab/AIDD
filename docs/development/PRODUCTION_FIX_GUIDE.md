# ç”Ÿäº§ç¯å¢ƒæ•°æ®åº“å­—æ®µé•¿åº¦é—®é¢˜ä¿®å¤æŒ‡å—

## é—®é¢˜æ¦‚è¿°

ç”Ÿäº§ç¯å¢ƒå‡ºç°AIè¾“å‡ºæ•°æ®è¿‡å¤§å¯¼è‡´çš„æ•°æ®åº“æ’å…¥å¤±è´¥ï¼š

```
(pymysql.err.DataError) (1406, "Data too long for column 'raw_output' at row 1")
```

**åŸå› åˆ†æï¼š**
- MySQLçš„`TEXT`ç±»å‹æœ€å¤§åªèƒ½å­˜å‚¨65,535å­—ç¬¦ï¼ˆ64KBï¼‰
- AIè¾“å‡ºçš„JSONæ•°æ®çº¦16ä¸‡å­—ç¬¦ï¼Œè¿œè¶…TEXTé™åˆ¶
- éœ€è¦å‡çº§ä¸º`LONGTEXT`ç±»å‹ï¼ˆæœ€å¤§4GBï¼‰

## ğŸš¨ ç´§æ€¥ä¿®å¤æ­¥éª¤

### 1. ç«‹å³å¤‡ä»½æ•°æ®åº“

```bash
# åˆ›å»ºå®Œæ•´å¤‡ä»½
mysqldump -u root -p ai_doc_test > backup_$(date +%Y%m%d_%H%M%S).sql

# éªŒè¯å¤‡ä»½å®Œæ•´æ€§
mysql -u root -p -e "SELECT COUNT(*) FROM ai_outputs;" ai_doc_test
```

### 2. åœæ­¢åº”ç”¨æœåŠ¡

```bash
# åœæ­¢åç«¯æœåŠ¡
pkill -f "python.*main.py"

# æˆ–è€…å¦‚æœä½¿ç”¨systemd
sudo systemctl stop ai-doc-backend
```

### 3. æ‰§è¡Œæ•°æ®åº“ç»“æ„è¿ç§»

```sql
-- è¿æ¥åˆ°MySQL
mysql -u root -p ai_doc_test

-- æŸ¥çœ‹å½“å‰è¡¨ç»“æ„
DESCRIBE ai_outputs;

-- æ‰§è¡Œå­—æ®µç±»å‹å‡çº§
ALTER TABLE ai_outputs MODIFY COLUMN input_text LONGTEXT NOT NULL;
ALTER TABLE ai_outputs MODIFY COLUMN raw_output LONGTEXT NOT NULL;

-- éªŒè¯ä¿®æ”¹ç»“æœ
DESCRIBE ai_outputs;

-- é€€å‡ºMySQL
EXIT;
```

### 4. éƒ¨ç½²ä¿®å¤åçš„ä»£ç 

```bash
# æ‹‰å–æœ€æ–°ä»£ç 
git pull origin main

# é‡å¯åº”ç”¨æœåŠ¡
python app/main.py

# æˆ–è€…å¦‚æœä½¿ç”¨systemd
sudo systemctl start ai-doc-backend
sudo systemctl status ai-doc-backend
```

### 5. éªŒè¯ä¿®å¤æ•ˆæœ

```bash
# è¿è¡Œè¿ç§»éªŒè¯è„šæœ¬
cd backend
python migrate_longtext.py --verify

# æµ‹è¯•å¤§æ•°æ®æ’å…¥
python migrate_longtext.py --test
```

## ğŸ”§ è‡ªåŠ¨åŒ–ä¿®å¤è„šæœ¬

æˆ‘ä»¬æä¾›äº†è‡ªåŠ¨åŒ–ä¿®å¤è„šæœ¬ï¼Œå¯ä»¥å®‰å…¨æ‰§è¡Œè¿ç§»ï¼š

```bash
# è¿›å…¥åç«¯ç›®å½•
cd backend

# è¿è¡Œè¿ç§»è„šæœ¬ï¼ˆä¼šæç¤ºå¤‡ä»½ï¼‰
python migrate_longtext.py

# å¼ºåˆ¶æ‰§è¡Œï¼ˆè·³è¿‡å¤‡ä»½æç¤ºï¼Œç”¨äºè‡ªåŠ¨åŒ–éƒ¨ç½²ï¼‰
python migrate_longtext.py --force

# ä»…éªŒè¯ä¸æ‰§è¡Œè¿ç§»
python migrate_longtext.py --verify

# æµ‹è¯•å¤§æ•°æ®æ’å…¥èƒ½åŠ›
python migrate_longtext.py --test
```

## ğŸ“Š ä¿®å¤å‰åå¯¹æ¯”

| é¡¹ç›® | ä¿®å¤å‰ | ä¿®å¤å |
|-----|--------|--------|
| `input_text` | TEXT (65,535å­—ç¬¦) | LONGTEXT (4GB) |
| `raw_output` | TEXT (65,535å­—ç¬¦) | LONGTEXT (4GB) |
| æ”¯æŒAIè¾“å‡ºå¤§å° | æœ€å¤§64KB | æœ€å¤§4GB |
| è·¨æ•°æ®åº“å…¼å®¹ | å¦ | æ˜¯ï¼ˆMySQLä½¿ç”¨LONGTEXTï¼ŒSQLiteä½¿ç”¨TEXTï¼‰ |

## ğŸ› ï¸ æ–°å¢åŠŸèƒ½

### 1. è·¨æ•°æ®åº“å…¼å®¹çš„å¤§æ–‡æœ¬ç±»å‹

```python
class LargeText(TypeDecorator):
    """è·¨æ•°æ®åº“çš„å¤§æ–‡æœ¬ç±»å‹ï¼ŒMySQLä½¿ç”¨LONGTEXTï¼ŒSQLiteä½¿ç”¨TEXT"""
    impl = Text
    cache_ok = True
    
    def load_dialect_impl(self, dialect):
        if dialect.name == 'mysql':
            return dialect.type_descriptor(LONGTEXT())
        else:
            return dialect.type_descriptor(Text())
```

### 2. å¢å¼ºçš„æ•°æ®åº“äº‹åŠ¡å¤„ç†

æ–°å¢ `app/core/database_utils.py` æä¾›ï¼š

- `safe_insert_ai_output()`: å®‰å…¨æ’å…¥AIè¾“å‡ºï¼Œè‡ªåŠ¨å¤„ç†å¤§æ•°æ®
- `safe_log_error()`: å®‰å…¨è®°å½•é”™è¯¯æ—¥å¿—
- `robust_db_session()`: å¢å¼ºçš„æ•°æ®åº“ä¼šè¯ç®¡ç†
- `cleanup_large_ai_outputs()`: æ¸…ç†å†å²å¤§æ•°æ®è®°å½•

### 3. è‡ªåŠ¨æ•°æ®æˆªæ–­ä¿æŠ¤

```python
# è‡ªåŠ¨æˆªæ–­è¿‡é•¿æ•°æ®ï¼Œé˜²æ­¢æ’å…¥å¤±è´¥
if len(raw_output) > max_text_length:
    logger.warning(f"åŸå§‹è¾“å‡ºè¿‡é•¿ï¼Œæˆªæ–­è‡³ {max_text_length} å­—ç¬¦")
    raw_output = raw_output[:max_text_length] + "...[æˆªæ–­]"
```

## âš ï¸ æ³¨æ„äº‹é¡¹

### è¿ç§»æ³¨æ„äº‹é¡¹

1. **å¤‡ä»½ä¼˜å…ˆ**ï¼šä»»ä½•æ“ä½œå‰éƒ½è¦å…ˆå¤‡ä»½æ•°æ®åº“
2. **åœæœè¿ç§»**ï¼šå»ºè®®åœ¨ä½å³°æœŸåœæœæ‰§è¡Œè¿ç§»
3. **æƒé™æ£€æŸ¥**ï¼šç¡®ä¿MySQLç”¨æˆ·æœ‰ALTERæƒé™
4. **ç©ºé—´ä¼°ç®—**ï¼šLONGTEXTä¼šå¢åŠ å­˜å‚¨ç©ºé—´éœ€æ±‚

### æ€§èƒ½å½±å“

1. **æŸ¥è¯¢æ€§èƒ½**ï¼šLONGTEXTå­—æ®µçš„æŸ¥è¯¢æ¯”TEXTç¨æ…¢
2. **ç´¢å¼•é™åˆ¶**ï¼šLONGTEXTä¸èƒ½ä½œä¸ºä¸»é”®æˆ–å”¯ä¸€é”®
3. **å†…å­˜ä½¿ç”¨**ï¼šå¤§æ–‡æœ¬ä¼šå¢åŠ å†…å­˜å ç”¨
4. **å¤‡ä»½æ—¶é—´**ï¼šå¤‡ä»½æ¢å¤æ—¶é—´ä¼šå¢åŠ 

### ç›‘æ§å»ºè®®

```bash
# ç›‘æ§å¤§æ•°æ®è®°å½•
mysql -u root -p -e "
SELECT 
    COUNT(*) as total_records,
    AVG(CHAR_LENGTH(raw_output)) as avg_size,
    MAX(CHAR_LENGTH(raw_output)) as max_size,
    SUM(CHAR_LENGTH(raw_output)) as total_size
FROM ai_outputs 
WHERE CHAR_LENGTH(raw_output) > 50000;
" ai_doc_test
```

## ğŸš€ éƒ¨ç½²åéªŒè¯

### 1. æ£€æŸ¥è¡¨ç»“æ„

```sql
mysql -u root -p -e "DESCRIBE ai_outputs;" ai_doc_test
```

æœŸæœ›è¾“å‡ºï¼š
```
+------------------+------------+------+-----+---------+----------------+
| Field            | Type       | Null | Key | Default | Extra          |
+------------------+------------+------+-----+---------+----------------+
| input_text       | longtext   | NO   |     | NULL    |                |
| raw_output       | longtext   | NO   |     | NULL    |                |
+------------------+------------+------+-----+---------+----------------+
```

### 2. æµ‹è¯•AIå¤„ç†æµç¨‹

1. ä¸Šä¼ ä¸€ä¸ªå¤§æ–‡æ¡£ï¼ˆ>100é¡µPDFï¼‰
2. è§‚å¯Ÿä»»åŠ¡å¤„ç†æ—¥å¿—
3. ç¡®è®¤ä¸å†å‡ºç°æ•°æ®é•¿åº¦é”™è¯¯

### 3. ç›‘æ§æ—¥å¿—

```bash
# æŸ¥çœ‹åº”ç”¨æ—¥å¿—
tail -f logs/app.log | grep -E "(DataError|Data too long)"

# ç¡®è®¤æ— é”™è¯¯è¾“å‡º
```

## ğŸ“ æ•…éšœæ’é™¤

### é—®é¢˜1ï¼šALTER TABLEæ‰§è¡Œæ—¶é—´è¿‡é•¿

**åŸå› **ï¼šè¡¨æ•°æ®é‡å¤§ï¼ŒALTERæ“ä½œéœ€è¦é‡å»ºè¡¨

**è§£å†³**ï¼š
```sql
-- æŸ¥çœ‹è¿›åº¦ï¼ˆå¦å¼€MySQLè¿æ¥ï¼‰
SHOW PROCESSLIST;

-- å¦‚æœéœ€è¦å–æ¶ˆæ“ä½œ
KILL QUERY [process_id];
```

### é—®é¢˜2ï¼šç£ç›˜ç©ºé—´ä¸è¶³

**åŸå› **ï¼šALTER TABLEéœ€è¦é¢å¤–ç£ç›˜ç©ºé—´

**è§£å†³**ï¼š
```bash
# æ£€æŸ¥ç£ç›˜ç©ºé—´
df -h

# æ¸…ç†ä¸´æ—¶æ–‡ä»¶
sudo rm -rf /tmp/mysql*
sudo rm -rf /var/tmp/mysql*
```

### é—®é¢˜3ï¼šæƒé™ä¸è¶³

**é”™è¯¯**ï¼š`Access denied for user`

**è§£å†³**ï¼š
```sql
-- èµ‹äºˆç”¨æˆ·ALTERæƒé™
GRANT ALTER ON ai_doc_test.* TO 'username'@'localhost';
FLUSH PRIVILEGES;
```

## ğŸ“ˆ é•¿æœŸä¼˜åŒ–å»ºè®®

### 1. æ•°æ®åˆ†å±‚å­˜å‚¨

è€ƒè™‘å°†å¤§å‹AIè¾“å‡ºå­˜å‚¨åˆ°æ–‡ä»¶ç³»ç»Ÿï¼š

```python
# å¤§äº1MBçš„æ•°æ®å­˜å‚¨åˆ°æ–‡ä»¶
if len(raw_output) > 1024 * 1024:
    file_path = f"data/ai_outputs/{task_id}_{timestamp}.json"
    with open(file_path, 'w') as f:
        f.write(raw_output)
    raw_output = f'{{"file_path": "{file_path}", "size": {len(raw_output)}}}'
```

### 2. æ•°æ®å‹ç¼©

```python
import gzip
import base64

# å‹ç¼©å¤§æ–‡æœ¬
compressed_data = gzip.compress(raw_output.encode())
raw_output = base64.b64encode(compressed_data).decode()
```

### 3. å®šæœŸæ¸…ç†

```bash
# æ·»åŠ å®šæ—¶ä»»åŠ¡æ¸…ç†å†å²å¤§æ•°æ®
0 2 * * * cd /path/to/backend && python -c "
from app.core.database_utils import cleanup_large_ai_outputs
from app.core.database import get_db
db = next(get_db())
cleanup_large_ai_outputs(db, days_old=30, max_size_mb=10)
"
```

---

## âœ… å®Œæˆæ£€æŸ¥æ¸…å•

- [ ] æ•°æ®åº“å·²å¤‡ä»½
- [ ] åº”ç”¨æœåŠ¡å·²åœæ­¢
- [ ] è¡¨ç»“æ„å·²å‡çº§ä¸ºLONGTEXT
- [ ] æ–°ä»£ç å·²éƒ¨ç½²
- [ ] æœåŠ¡å·²é‡å¯
- [ ] è¿ç§»ç»“æœå·²éªŒè¯
- [ ] å¤§æ•°æ®æ’å…¥æµ‹è¯•é€šè¿‡
- [ ] åº”ç”¨æ—¥å¿—æ— é”™è¯¯
- [ ] ç›‘æ§å‘Šè­¦å·²é…ç½®

## ğŸ“ æŠ€æœ¯æ”¯æŒ

å¦‚é‡åˆ°å…¶ä»–é—®é¢˜ï¼Œè¯·æä¾›ï¼š

1. å®Œæ•´çš„é”™è¯¯æ—¥å¿—
2. æ•°æ®åº“ç‰ˆæœ¬ä¿¡æ¯ï¼š`SELECT VERSION();`
3. è¡¨ç»“æ„ä¿¡æ¯ï¼š`DESCRIBE ai_outputs;`
4. ç£ç›˜ç©ºé—´ä¿¡æ¯ï¼š`df -h`
5. å†…å­˜ä½¿ç”¨æƒ…å†µï¼š`free -h`