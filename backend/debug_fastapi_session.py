#!/usr/bin/env python3
"""
FastAPIæ•°æ®åº“ä¼šè¯é˜»å¡é—®é¢˜è°ƒè¯•
é‡ç‚¹åˆ†æ16ç§’é˜»å¡çš„æ ¹æœ¬åŸå› 
"""
import time
import threading
import asyncio
from concurrent.futures import ThreadPoolExecutor

def test_get_db_generator():
    """æµ‹è¯•get_dbç”Ÿæˆå™¨çš„è¡Œä¸º"""
    print("ğŸ” æµ‹è¯•get_dbç”Ÿæˆå™¨æ€§èƒ½...")
    
    from app.core.database import get_db
    
    times = []
    for i in range(10):
        start = time.time()
        
        # æ¨¡æ‹ŸFastAPIçš„ä¾èµ–æ³¨å…¥è°ƒç”¨
        db_generator = get_db()
        try:
            db = next(db_generator)
            # æ¨¡æ‹Ÿæ•°æ®åº“æ“ä½œ
            from sqlalchemy import text
            db.execute(text("SELECT 1"))
            
        except Exception as e:
            print(f"âŒ get_dbæµ‹è¯• {i} å¤±è´¥: {e}")
        finally:
            try:
                next(db_generator, None)  # è§¦å‘finallyå—
            except StopIteration:
                pass
        
        elapsed = (time.time() - start) * 1000
        times.append(elapsed)
        print(f"get_dbæµ‹è¯• {i}: {elapsed:.1f}ms")
    
    if times:
        avg_time = sum(times) / len(times)
        max_time = max(times)
        print(f"ğŸ“Š get_dbç»Ÿè®¡: å¹³å‡ {avg_time:.1f}ms, æœ€å¤§ {max_time:.1f}ms")

def test_concurrent_fastapi_sessions():
    """æµ‹è¯•å¹¶å‘FastAPIä¼šè¯ï¼ˆæ¨¡æ‹ŸçœŸå®åœºæ™¯ï¼‰"""
    print("\nğŸ” æµ‹è¯•å¹¶å‘FastAPIä¼šè¯...")
    
    results = []
    
    def simulate_fastapi_request(request_id: int):
        """æ¨¡æ‹Ÿå•ä¸ªFastAPIè¯·æ±‚"""
        from app.core.database import get_db
        
        start = time.time()
        try:
            # æ¨¡æ‹ŸFastAPIè¯·æ±‚å¤„ç†
            db_generator = get_db()
            db = next(db_generator)
            
            try:
                # æ¨¡æ‹Ÿå¹¶å‘æ£€æŸ¥
                from app.services.concurrency_service import concurrency_service
                from app.models.user import User
                
                user = db.query(User).first()
                if user:
                    allowed, status_info = concurrency_service.check_concurrency_limits(
                        db, user, requested_tasks=12, raise_exception=False
                    )
                
                # æ¨¡æ‹Ÿå…¶ä»–æ•°æ®åº“æ“ä½œ
                from sqlalchemy import text
                db.execute(text("SELECT COUNT(*) FROM tasks"))
                
                # æ¨¡æ‹Ÿä»»åŠ¡åˆ†é¡µæŸ¥è¯¢
                time.sleep(0.05)  # æ¨¡æ‹ŸæŸ¥è¯¢æ—¶é—´
                
            finally:
                try:
                    next(db_generator, None)  # è§¦å‘finallyå—
                except StopIteration:
                    pass
                    
        except Exception as e:
            print(f"âŒ æ¨¡æ‹Ÿè¯·æ±‚ {request_id} å¤±è´¥: {e}")
        
        elapsed = (time.time() - start) * 1000
        results.append(elapsed)
        print(f"FastAPIè¯·æ±‚ {request_id}: {elapsed:.1f}ms")
        return elapsed
    
    # ä½¿ç”¨çº¿ç¨‹æ¨¡æ‹Ÿå¹¶å‘FastAPIè¯·æ±‚
    threads = []
    start_time = time.time()
    
    for i in range(12):  # æ¨¡æ‹Ÿ12ä¸ªå¹¶å‘è¯·æ±‚
        t = threading.Thread(target=simulate_fastapi_request, args=(i,))
        threads.append(t)
        t.start()
    
    # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
    for t in threads:
        t.join()
    
    total_time = (time.time() - start_time) * 1000
    
    if results:
        avg_time = sum(results) / len(results)
        max_time = max(results)
        min_time = min(results)
        print(f"ğŸ“Š å¹¶å‘FastAPIæµ‹è¯•: æ€»è€—æ—¶ {total_time:.1f}ms")
        print(f"   å•è¯·æ±‚ç»Ÿè®¡: å¹³å‡ {avg_time:.1f}ms, æœ€å¤§ {max_time:.1f}ms, æœ€å° {min_time:.1f}ms")

def test_mixed_workload():
    """æµ‹è¯•æ··åˆå·¥ä½œè´Ÿè½½ï¼ˆæ¨¡æ‹ŸçœŸå®ç”Ÿäº§åœºæ™¯ï¼‰"""
    print("\nğŸ” æµ‹è¯•æ··åˆå·¥ä½œè´Ÿè½½...")
    
    # æ¨¡æ‹Ÿç”Ÿäº§ç¯å¢ƒçš„æ··åˆè¯·æ±‚åœºæ™¯
    def batch_task_creation():
        """æ¨¡æ‹Ÿæ‰¹é‡ä»»åŠ¡åˆ›å»º"""
        from app.core.database import get_independent_db_session, close_independent_db_session
        import asyncio
        
        async def create_task(task_id: int):
            session = get_independent_db_session()
            try:
                from sqlalchemy import text
                session.execute(text("SELECT COUNT(*) FROM tasks"))
                await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿä»»åŠ¡å¤„ç†
                session.commit()
            except Exception as e:
                print(f"âŒ æ‰¹é‡ä»»åŠ¡ {task_id} å¤±è´¥: {e}")
            finally:
                close_independent_db_session(session, f"æ‰¹é‡-{task_id}")
        
        # å¼‚æ­¥åˆ›å»º12ä¸ªä»»åŠ¡
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            semaphore = asyncio.Semaphore(5)
            async def controlled_create(task_id: int):
                async with semaphore:
                    return await create_task(task_id)
            
            start = time.time()
            loop.run_until_complete(asyncio.gather(
                *[controlled_create(i) for i in range(12)]
            ))
            elapsed = (time.time() - start) * 1000
            print(f"ğŸš€ æ‰¹é‡ä»»åŠ¡åˆ›å»ºå®Œæˆ: {elapsed:.1f}ms")
        finally:
            loop.close()
    
    def concurrent_api_requests():
        """æ¨¡æ‹Ÿå¹¶å‘APIè¯·æ±‚"""
        simulate_fastapi_request(99)
    
    # åŒæ—¶è¿è¡Œæ‰¹é‡ä»»åŠ¡åˆ›å»ºå’ŒAPIè¯·æ±‚
    batch_thread = threading.Thread(target=batch_task_creation)
    api_threads = [threading.Thread(target=concurrent_api_requests) for _ in range(5)]
    
    start_time = time.time()
    
    # å¯åŠ¨æ‰¹é‡ä»»åŠ¡åˆ›å»º
    batch_thread.start()
    
    # ç¨åå¯åŠ¨APIè¯·æ±‚
    time.sleep(0.05)
    for t in api_threads:
        t.start()
    
    # ç­‰å¾…æ‰€æœ‰å®Œæˆ
    batch_thread.join()
    for t in api_threads:
        t.join()
    
    total_time = (time.time() - start_time) * 1000
    print(f"ğŸ“Š æ··åˆè´Ÿè½½æµ‹è¯•å®Œæˆ: æ€»è€—æ—¶ {total_time:.1f}ms")

def analyze_db_engine_type():
    """åˆ†ææ•°æ®åº“å¼•æ“é…ç½®"""
    print("\nğŸ” åˆ†ææ•°æ®åº“å¼•æ“é…ç½®...")
    
    from app.core.database import engine
    
    print(f"æ•°æ®åº“å¼•æ“: {type(engine)}")
    print(f"æ•°æ®åº“URL: {engine.url}")
    print(f"å¼•æ“é…ç½®: {engine.url.query}")
    
    # æ£€æŸ¥è¿æ¥æ± ç±»å‹
    pool = engine.pool
    print(f"è¿æ¥æ± ç±»å‹: {type(pool)}")
    print(f"è¿æ¥æ± ç±»å: {pool.__class__.__name__}")

if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ•µï¸ FastAPIæ•°æ®åº“ä¼šè¯é˜»å¡è°ƒè¯•")
    print("=" * 60)
    
    analyze_db_engine_type()
    test_get_db_generator()
    test_concurrent_fastapi_sessions()
    test_mixed_workload()
    
    print("=" * 60)
    print("ğŸ¯ FastAPIä¼šè¯è°ƒè¯•å®Œæˆ")
    print("=" * 60)