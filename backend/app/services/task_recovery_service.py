"""
ä»»åŠ¡æ¢å¤æœåŠ¡
å¤„ç†ç³»ç»Ÿé‡å¯åçš„ä»»åŠ¡æ¢å¤ã€ä»»åŠ¡è°ƒåº¦å’Œå¥åº·æ£€æŸ¥
"""
import asyncio
import logging
import time
from datetime import datetime, timedelta
from typing import List, Optional, Dict, Any
from sqlalchemy.orm import Session
from sqlalchemy import and_, or_

from app.core.database import SessionLocal, get_db
from app.models.task import Task
from app.repositories.task import TaskRepository
from app.repositories.ai_model import AIModelRepository
from app.services.concurrency_service import concurrency_service
from app.services.new_task_processor import NewTaskProcessor
from app.core.config import get_settings


logger = logging.getLogger(__name__)


class TaskRecoveryService:
    """ä»»åŠ¡æ¢å¤æœåŠ¡"""
    
    def __init__(self):
        self.settings = get_settings()
        self.processing_timeout = self.settings.task_processing_config.get('processing_timeout', 3600)  # é»˜è®¤1å°æ—¶
        self.recovery_enabled = self.settings.task_processing_config.get('recovery_enabled', True)
        
    async def recover_tasks_on_startup(self, db: Session = None) -> int:
        """
        ç³»ç»Ÿå¯åŠ¨æ—¶æ¢å¤ä»»åŠ¡
        
        Returns:
            æ¢å¤çš„ä»»åŠ¡æ•°é‡
        """
        if not self.recovery_enabled:
            logger.info("ä»»åŠ¡æ¢å¤åŠŸèƒ½å·²ç¦ç”¨")
            return 0
            
        # å¦‚æœæ²¡æœ‰æä¾›æ•°æ®åº“ä¼šè¯ï¼Œåˆ›å»ºæ–°çš„
        if db is None:
            db = SessionLocal()
            should_close_db = True
        else:
            should_close_db = False
            
        try:
            logger.info("ğŸ”„ å¼€å§‹ç³»ç»Ÿå¯åŠ¨ä»»åŠ¡æ¢å¤...")
            
            task_repo = TaskRepository(db)
            
            # 1. é‡ç½®åƒµå°¸å¤„ç†ä»»åŠ¡
            zombie_count = await self._reset_zombie_processing_tasks(task_repo)
            
            # 2. è°ƒåº¦å¾…å¤„ç†ä»»åŠ¡
            scheduled_count = await self._schedule_pending_tasks(db, task_repo)
            
            total_recovered = zombie_count + scheduled_count
            
            logger.info(f"âœ… ä»»åŠ¡æ¢å¤å®Œæˆ: é‡ç½®åƒµå°¸ä»»åŠ¡ {zombie_count} ä¸ªï¼Œè°ƒåº¦å¾…å¤„ç†ä»»åŠ¡ {scheduled_count} ä¸ª")
            
            return total_recovered
            
        except Exception as e:
            logger.error(f"âŒ ä»»åŠ¡æ¢å¤å¤±è´¥: {e}")
            raise
        finally:
            if should_close_db:
                db.close()
    
    async def _reset_zombie_processing_tasks(self, task_repo: TaskRepository) -> int:
        """
        é‡ç½®åƒµå°¸å¤„ç†ä»»åŠ¡ï¼ˆå¤„ç†ä¸­ä½†å¯èƒ½å·²åœæ­¢çš„ä»»åŠ¡ï¼‰
        
        Returns:
            é‡ç½®çš„ä»»åŠ¡æ•°é‡
        """
        try:
            # æŸ¥æ‰¾å¯èƒ½çš„åƒµå°¸ä»»åŠ¡ï¼šçŠ¶æ€ä¸ºprocessingçš„æ‰€æœ‰ä»»åŠ¡ï¼ˆæœåŠ¡é‡å¯åï¼Œæ‰€æœ‰processingä»»åŠ¡éƒ½æ˜¯åƒµå°¸ä»»åŠ¡ï¼‰
            # è¿™é‡Œä¸ç”¨æ—¶é—´åˆ¤æ–­ï¼Œå› ä¸ºæœåŠ¡é‡å¯æ„å‘³ç€æ‰€æœ‰processingä»»åŠ¡éƒ½åº”è¯¥è¢«é‡ç½®
            zombie_tasks = task_repo.db.query(Task).filter(Task.status == 'processing').all()
            
            reset_count = 0
            for task in zombie_tasks:
                logger.warning(f"ğŸ§Ÿ å‘ç°åƒµå°¸ä»»åŠ¡: {task.id} ({task.title})ï¼Œæ ‡è®°ä¸ºå¤±è´¥çŠ¶æ€ï¼ˆæœåŠ¡é‡å¯å¯¼è‡´ä¸­æ–­ï¼‰")
                task_repo.update(
                    task.id, 
                    status='failed', 
                    progress=0, 
                    error_message="æœåŠ¡é‡å¯å¯¼è‡´ä»»åŠ¡ä¸­æ–­ï¼Œè¯·æ‰‹åŠ¨é‡è¯•"
                )
                reset_count += 1
            
            if reset_count > 0:
                logger.info(f"âœ… å‘ç°å¹¶é‡ç½®äº† {reset_count} ä¸ªåƒµå°¸ä»»åŠ¡ï¼ˆå› æœåŠ¡é‡å¯ä¸­æ–­ï¼‰")
            
            return reset_count
            
        except Exception as e:
            logger.error(f"âŒ é‡ç½®åƒµå°¸ä»»åŠ¡å¤±è´¥: {e}")
            return 0
    
    async def _schedule_pending_tasks(self, db: Session, task_repo: TaskRepository) -> int:
        """
        è°ƒåº¦å¾…å¤„ç†ä»»åŠ¡
        
        Returns:
            è°ƒåº¦çš„ä»»åŠ¡æ•°é‡
        """
        try:
            # è·å–æ‰€æœ‰å¾…å¤„ç†ä»»åŠ¡
            pending_tasks = task_repo.get_pending_tasks()
            
            if not pending_tasks:
                logger.info("æ²¡æœ‰å¾…å¤„ç†çš„ä»»åŠ¡")
                return 0
                
            logger.info(f"ğŸ“‹ å‘ç° {len(pending_tasks)} ä¸ªå¾…å¤„ç†ä»»åŠ¡")
            
            scheduled_count = 0
            
            for task in pending_tasks:
                try:
                    # æ£€æŸ¥ç³»ç»Ÿå¹¶å‘é™åˆ¶
                    system_allowed, _ = concurrency_service.check_system_concurrency_limit(db, 1)
                    
                    if not system_allowed:
                        logger.info(f"ğŸš¦ ç³»ç»Ÿå¹¶å‘é™åˆ¶å·²è¾¾ä¸Šé™ï¼Œæš‚åœè°ƒåº¦å‰©ä½™ä»»åŠ¡")
                        break
                    
                    # æ£€æŸ¥ç”¨æˆ·å¹¶å‘é™åˆ¶ï¼ˆå¦‚æœä»»åŠ¡æœ‰ç”¨æˆ·IDï¼‰
                    if task.user_id:
                        from app.repositories.user import UserRepository
                        user_repo = UserRepository(db)
                        user = user_repo.get_by_id(task.user_id)
                        
                        if user:
                            user_allowed, _ = concurrency_service.check_user_concurrency_limit(db, user, 1)
                            if not user_allowed:
                                logger.info(f"ğŸš¦ ç”¨æˆ· {user.uid} å¹¶å‘é™åˆ¶å·²è¾¾ä¸Šé™ï¼Œè·³è¿‡ä»»åŠ¡ {task.id}")
                                continue
                    
                    # å¯åŠ¨ä»»åŠ¡å¤„ç†
                    await self._start_task_processing(task.id)
                    scheduled_count += 1
                    logger.info(f"ğŸš€ å·²è°ƒåº¦ä»»åŠ¡: {task.id} ({task.title})")
                    
                    # æ·»åŠ çŸ­æš‚å»¶è¿Ÿï¼Œé¿å…è¿‡å¿«å¯åŠ¨ä»»åŠ¡
                    await asyncio.sleep(0.1)
                    
                except Exception as e:
                    logger.error(f"âŒ è°ƒåº¦ä»»åŠ¡ {task.id} å¤±è´¥: {e}")
                    continue
            
            logger.info(f"âœ… è°ƒåº¦äº† {scheduled_count} ä¸ªå¾…å¤„ç†ä»»åŠ¡")
            return scheduled_count
            
        except Exception as e:
            logger.error(f"âŒ è°ƒåº¦å¾…å¤„ç†ä»»åŠ¡å¤±è´¥: {e}")
            return 0
    
    async def _start_task_processing(self, task_id: int):
        """å¯åŠ¨ä»»åŠ¡å¤„ç†"""
        try:
            processor = NewTaskProcessor()
            # ä½¿ç”¨create_taskåœ¨åå°æ‰§è¡Œï¼Œä¸ç­‰å¾…å®Œæˆ
            asyncio.create_task(processor.process_task(task_id))
        except Exception as e:
            logger.error(f"âŒ å¯åŠ¨ä»»åŠ¡å¤„ç†å™¨å¤±è´¥ (task_id={task_id}): {e}")
            raise
    
    async def retry_task(self, task_id: int, db: Session = None) -> bool:
        """
        é‡è¯•æŒ‡å®šçš„ä»»åŠ¡
        
        Args:
            task_id: ä»»åŠ¡ID
            db: æ•°æ®åº“ä¼šè¯ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            æ˜¯å¦æˆåŠŸå¯åŠ¨é‡è¯•
        """
        if db is None:
            db = SessionLocal()
            should_close_db = True
        else:
            should_close_db = False
            
        try:
            task_repo = TaskRepository(db)
            task = task_repo.get_by_id(task_id)
            
            if not task:
                logger.warning(f"âŒ é‡è¯•å¤±è´¥: ä»»åŠ¡ {task_id} ä¸å­˜åœ¨")
                return False
            
            # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€æ˜¯å¦å¯é‡è¯•
            if task.status not in ['failed', 'completed']:
                logger.warning(f"âŒ é‡è¯•å¤±è´¥: ä»»åŠ¡ {task_id} çŠ¶æ€ä¸º {task.status}ï¼Œä¸æ”¯æŒé‡è¯•")
                return False
            
            logger.info(f"ğŸ”„ å¼€å§‹é‡è¯•ä»»åŠ¡: {task_id} ({task.title})")
            
            # é‡ç½®ä»»åŠ¡çŠ¶æ€
            task_repo.update(
                task_id, 
                status='pending', 
                progress=0, 
                error_message=None,
                completed_at=None,
                processing_time=None
            )
            
            # æ¸…ç†ç›¸å…³æ•°æ®ï¼ˆä¿ç•™æ–‡ä»¶ä¿¡æ¯ï¼‰
            await self._cleanup_task_results(task_id, db)
            
            # æ£€æŸ¥å¹¶å‘é™åˆ¶
            system_allowed, _ = concurrency_service.check_system_concurrency_limit(db, 1)
            if not system_allowed:
                logger.info(f"ğŸš¦ ç³»ç»Ÿå¹¶å‘é™åˆ¶å·²è¾¾ä¸Šé™ï¼Œä»»åŠ¡ {task_id} å·²é‡ç½®ä¸ºpendingçŠ¶æ€ï¼Œç­‰å¾…è°ƒåº¦")
                return True
            
            # æ£€æŸ¥ç”¨æˆ·å¹¶å‘é™åˆ¶
            if task.user_id:
                from app.repositories.user import UserRepository
                user_repo = UserRepository(db)
                user = user_repo.get_by_id(task.user_id)
                
                if user:
                    user_allowed, _ = concurrency_service.check_user_concurrency_limit(db, user, 1)
                    if not user_allowed:
                        logger.info(f"ğŸš¦ ç”¨æˆ·å¹¶å‘é™åˆ¶å·²è¾¾ä¸Šé™ï¼Œä»»åŠ¡ {task_id} å·²é‡ç½®ä¸ºpendingçŠ¶æ€ï¼Œç­‰å¾…è°ƒåº¦")
                        return True
            
            # ç«‹å³å¯åŠ¨å¤„ç†
            await self._start_task_processing(task_id)
            logger.info(f"âœ… ä»»åŠ¡ {task_id} é‡è¯•å¯åŠ¨æˆåŠŸ")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ é‡è¯•ä»»åŠ¡ {task_id} å¤±è´¥: {e}")
            return False
        finally:
            if should_close_db:
                db.close()
    
    async def _cleanup_task_results(self, task_id: int, db: Session):
        """æ¸…ç†ä»»åŠ¡çš„ç»“æœæ•°æ®ï¼ˆä¿ç•™æ–‡ä»¶ï¼‰"""
        try:
            # åˆ é™¤ä»»åŠ¡ç›¸å…³çš„é—®é¢˜ã€AIè¾“å‡ºå’Œæ—¥å¿—
            from app.models import Issue, AIOutput, TaskLog
            
            db.query(Issue).filter(Issue.task_id == task_id).delete()
            db.query(AIOutput).filter(AIOutput.task_id == task_id).delete()
            db.query(TaskLog).filter(TaskLog.task_id == task_id).delete()
            
            db.commit()
            logger.info(f"âœ… å·²æ¸…ç†ä»»åŠ¡ {task_id} çš„å†å²ç»“æœæ•°æ®")
            
        except Exception as e:
            logger.error(f"âŒ æ¸…ç†ä»»åŠ¡ {task_id} ç»“æœæ•°æ®å¤±è´¥: {e}")
            db.rollback()
    
    async def check_and_recover_timeout_tasks(self, db: Session = None) -> int:
        """
        æ£€æŸ¥å¹¶æ¢å¤è¶…æ—¶ä»»åŠ¡
        
        Returns:
            æ¢å¤çš„ä»»åŠ¡æ•°é‡
        """
        if db is None:
            db = SessionLocal()
            should_close_db = True
        else:
            should_close_db = False
            
        try:
            task_repo = TaskRepository(db)
            timeout_threshold = datetime.utcnow() - timedelta(seconds=self.processing_timeout)
            
            # æŸ¥æ‰¾è¶…æ—¶çš„å¤„ç†ä¸­ä»»åŠ¡ï¼ˆåŸºäºcreated_atå­—æ®µï¼‰
            timeout_tasks = task_repo.db.query(Task).filter(
                and_(
                    Task.status == 'processing',
                    Task.created_at < timeout_threshold
                )
            ).all()
            
            recovered_count = 0
            for task in timeout_tasks:
                logger.warning(f"â° å‘ç°è¶…æ—¶ä»»åŠ¡: {task.id} ({task.title})ï¼Œæ ‡è®°ä¸ºå¤±è´¥")
                task_repo.update(
                    task.id, 
                    status='failed', 
                    error_message=f"ä»»åŠ¡å¤„ç†è¶…æ—¶ (>{self.processing_timeout}ç§’)"
                )
                recovered_count += 1
            
            if recovered_count > 0:
                logger.info(f"âœ… æ¢å¤äº† {recovered_count} ä¸ªè¶…æ—¶ä»»åŠ¡")
            
            return recovered_count
            
        except Exception as e:
            logger.error(f"âŒ æ£€æŸ¥è¶…æ—¶ä»»åŠ¡å¤±è´¥: {e}")
            return 0
        finally:
            if should_close_db:
                db.close()
    
    async def schedule_pending_tasks_if_available(self, db: Session = None) -> int:
        """
        åœ¨èµ„æºå¯ç”¨æ—¶è°ƒåº¦å¾…å¤„ç†ä»»åŠ¡
        
        Returns:
            è°ƒåº¦çš„ä»»åŠ¡æ•°é‡
        """
        if db is None:
            db = SessionLocal()
            should_close_db = True
        else:
            should_close_db = False
            
        try:
            # æ£€æŸ¥ç³»ç»Ÿæ˜¯å¦æœ‰å¯ç”¨èµ„æº
            system_allowed, system_info = concurrency_service.check_system_concurrency_limit(db, 1)
            
            if not system_allowed:
                return 0
                
            # è·å–å¯ç”¨çš„å¹¶å‘æ§½ä½æ•°
            available_slots = system_info['available_slots']
            
            # è°ƒåº¦å¾…å¤„ç†ä»»åŠ¡
            task_repo = TaskRepository(db)
            return await self._schedule_pending_tasks_with_limit(db, task_repo, available_slots)
            
        except Exception as e:
            logger.error(f"âŒ èµ„æºå¯ç”¨æ—¶è°ƒåº¦ä»»åŠ¡å¤±è´¥: {e}")
            return 0
        finally:
            if should_close_db:
                db.close()
    
    async def _schedule_pending_tasks_with_limit(self, db: Session, task_repo: TaskRepository, max_tasks: int) -> int:
        """æŒ‰é™åˆ¶è°ƒåº¦å¾…å¤„ç†ä»»åŠ¡"""
        pending_tasks = task_repo.get_pending_tasks()
        
        if not pending_tasks:
            return 0
            
        scheduled_count = 0
        
        for task in pending_tasks[:max_tasks]:  # é™åˆ¶è°ƒåº¦æ•°é‡
            try:
                # æ£€æŸ¥ç”¨æˆ·å¹¶å‘é™åˆ¶
                if task.user_id:
                    from app.repositories.user import UserRepository
                    user_repo = UserRepository(db)
                    user = user_repo.get_by_id(task.user_id)
                    
                    if user:
                        user_allowed, _ = concurrency_service.check_user_concurrency_limit(db, user, 1)
                        if not user_allowed:
                            continue
                
                # å¯åŠ¨ä»»åŠ¡å¤„ç†
                await self._start_task_processing(task.id)
                scheduled_count += 1
                
                # çŸ­æš‚å»¶è¿Ÿ
                await asyncio.sleep(0.1)
                
            except Exception as e:
                logger.error(f"âŒ è°ƒåº¦ä»»åŠ¡ {task.id} å¤±è´¥: {e}")
                continue
        
        return scheduled_count
    
    def get_recovery_status(self, db: Session = None) -> Dict[str, Any]:
        """
        è·å–ä»»åŠ¡æ¢å¤çŠ¶æ€ä¿¡æ¯
        
        Returns:
            æ¢å¤çŠ¶æ€ä¿¡æ¯
        """
        if db is None:
            db = SessionLocal()
            should_close_db = True
        else:
            should_close_db = False
            
        try:
            task_repo = TaskRepository(db)
            
            # ç»Ÿè®¡å„çŠ¶æ€ä»»åŠ¡æ•°é‡
            from sqlalchemy import func
            status_counts = task_repo.db.query(
                Task.status,
                func.count(Task.id).label('count')
            ).group_by(Task.status).all()
            
            status_dict = {status: count for status, count in status_counts}
            
            # æ£€æŸ¥å¯èƒ½çš„åƒµå°¸ä»»åŠ¡
            timeout_threshold = datetime.utcnow() - timedelta(seconds=self.processing_timeout)
            potential_zombie_count = task_repo.db.query(Task).filter(
                and_(
                    Task.status == 'processing',
                    Task.created_at < timeout_threshold
                )
            ).count()
            
            return {
                'recovery_enabled': self.recovery_enabled,
                'processing_timeout': self.processing_timeout,
                'task_counts': status_dict,
                'potential_zombie_tasks': potential_zombie_count,
                'system_concurrency': concurrency_service.get_concurrency_status(db)
            }
            
        except Exception as e:
            logger.error(f"âŒ è·å–æ¢å¤çŠ¶æ€å¤±è´¥: {e}")
            return {'error': str(e)}
        finally:
            if should_close_db:
                db.close()


# åˆ›å»ºå…¨å±€å®ä¾‹
task_recovery_service = TaskRecoveryService()