"""é™æ€é—®é¢˜æ£€æµ‹æœåŠ¡ - è´Ÿè´£æ£€æµ‹æ–‡æ¡£ä¸­çš„è´¨é‡é—®é¢˜"""
import json
import re
import time
import logging
import asyncio
from typing import List, Dict, Optional, Callable, Any
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
try:
    from langchain_core.output_parsers import PydanticOutputParser
except ImportError:
    from langchain.output_parsers import PydanticOutputParser
from pydantic import BaseModel, Field
from sqlalchemy.orm import Session

from app.services.prompt_loader import prompt_loader
from app.models.ai_output import AIOutput
from app.core.config import get_settings
from app.utils.ai_retry_parser import ai_retry_parser, RetryConfig


# å®šä¹‰ç»“æ„åŒ–è¾“å‡ºæ¨¡å‹
class DocumentIssue(BaseModel):
    """æ–‡æ¡£é—®é¢˜æ¨¡å‹"""
    type: str = Field(description="é—®é¢˜ç±»å‹ï¼š2-6ä¸ªå­—çš„ç®€çŸ­æè¿°ï¼Œå¦‚'é”™åˆ«å­—'ã€'è¯­æ³•é”™è¯¯'ã€'é€»è¾‘ä¸é€š'ã€'å†…å®¹ç¼ºå¤±'ã€'æ ¼å¼é—®é¢˜'ç­‰ï¼Œç”±æ¨¡å‹æ ¹æ®å®é™…é—®é¢˜è‡ªè¡Œåˆ¤æ–­")
    description: str = Field(description="è¯¦ç»†çš„é—®é¢˜æè¿°ï¼Œæ¸…æ™°è¯´æ˜å…·ä½“é—®é¢˜ç‚¹ï¼ŒåŒ…æ‹¬é—®é¢˜çš„è¡¨ç°ã€ä½ç½®å’Œå½±å“ï¼Œè‡³å°‘30å­—ä»¥ä¸Š")
    location: str = Field(description="é—®é¢˜æ‰€åœ¨ä½ç½®")
    severity: str = Field(description="åŸºäºç”¨æˆ·å½±å“ç¨‹åº¦çš„ä¸¥é‡ç­‰çº§ï¼šè‡´å‘½ï¼ˆå¯¼è‡´æ— æ³•ä½¿ç”¨æˆ–ä¸¥é‡è¯¯å¯¼ï¼‰/ä¸¥é‡ï¼ˆå½±å“æ ¸å¿ƒåŠŸèƒ½ç†è§£ï¼‰/ä¸€èˆ¬ï¼ˆå½±å“è´¨é‡ä½†ä¸å½±å“ç†è§£ï¼‰/æç¤ºï¼ˆä¼˜åŒ–å»ºè®®ï¼‰")
    confidence: float = Field(description="æ¨¡å‹å¯¹æ­¤é—®é¢˜åˆ¤å®šçš„ç½®ä¿¡åº¦ï¼ŒèŒƒå›´0.0-1.0", default=0.8)
    suggestion: str = Field(description="ä¿®æ”¹å»ºè®®ï¼šç›´æ¥ç»™å‡ºä¿®æ”¹åçš„å®Œæ•´å†…å®¹ï¼Œè€Œä¸æ˜¯æè¿°å¦‚ä½•ä¿®æ”¹")
    original_text: str = Field(description="åŒ…å«é—®é¢˜çš„åŸæ–‡å†…å®¹å…³é”®ç‰‡æ®µï¼Œ10~30å­—ç¬¦", default="")
    user_impact: str = Field(description="è¯¥é—®é¢˜å¯¹ç”¨æˆ·é˜…è¯»ç†è§£çš„å½±å“ï¼Œ10~30å­—ç¬¦", default="")
    reasoning: str = Field(description="åˆ¤å®šä¸ºé—®é¢˜çš„è¯¦ç»†åˆ†æå’Œæ¨ç†è¿‡ç¨‹ï¼Œ20~100å­—ç¬¦", default="")
    context: str = Field(description="é—®é¢˜æ‰€åœ¨çš„ä¸Šä¸‹æ–‡ç¯å¢ƒï¼ˆ20-200å­—ï¼‰ï¼šè¯·ä¸¥æ ¼è¾“å‡ºåŒ…å«åŸæ–‡ç‰‡æ®µçš„ä¸Šä¸‹æ–‡æ®µè½çš„å®Œæ•´å†…å®¹", default="")


class DocumentIssues(BaseModel):
    """æ–‡æ¡£é—®é¢˜åˆ—è¡¨"""
    issues: List[DocumentIssue] = Field(description="å‘ç°çš„æ‰€æœ‰é—®é¢˜", default=[])


class IssueDetector:
    """é™æ€é—®é¢˜æ£€æµ‹æœåŠ¡ - ä¸“é—¨è´Ÿè´£æ–‡æ¡£è´¨é‡é—®é¢˜æ£€æµ‹"""
    
    def __init__(self, model_config: Dict, db_session: Optional[Session] = None):
        """
        åˆå§‹åŒ–é—®é¢˜æ£€æµ‹å™¨
        
        Args:
            model_config: AIæ¨¡å‹é…ç½®
            db_session: æ•°æ®åº“ä¼šè¯
        """
        self.db = db_session
        self.model_config = model_config
        
        # åˆå§‹åŒ–æ—¥å¿—
        self.logger = logging.getLogger(f"issue_detector.{id(self)}")
        self.logger.setLevel(logging.INFO)
        
        # ç¡®ä¿æ—¥å¿—èƒ½è¾“å‡ºåˆ°æ§åˆ¶å°
        if not self.logger.handlers:
            console_handler = logging.StreamHandler()
            console_handler.setLevel(logging.INFO)
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            console_handler.setFormatter(formatter)
            self.logger.addHandler(console_handler)
        
        # ä»é…ç½®ä¸­æå–å‚æ•° - å…¼å®¹ä¸¤ç§é…ç½®æ ¼å¼
        if 'config' in model_config:
            # æ–°æ ¼å¼ï¼šmodel_configåŒ…å«providerå’Œconfig
            config = model_config['config']
            self.provider = model_config.get('provider', 'openai')
        else:
            # æ—§æ ¼å¼ï¼šmodel_configç›´æ¥åŒ…å«é…ç½®
            config = model_config
            self.provider = model_config.get('provider', 'openai')
        
        self.api_key = config.get('api_key')
        self.api_base = config.get('base_url')
        self.model_name = config.get('model')
        self.temperature = config.get('temperature', 0.3)
        self.max_tokens = config.get('max_tokens', 4000)
        self.timeout = config.get('timeout', 60)
        self.max_retries = config.get('max_retries', 3)
        
        # é…ç½®JSONè§£æé‡è¯•
        self.retry_config = RetryConfig(
            max_retries=config.get('json_parse_retries', 3),
            base_delay=config.get('json_retry_delay', 1.0),
            backoff_multiplier=2.0,
            max_delay=10.0
        )
        
        self.logger.info(f"ğŸ” é—®é¢˜æ£€æµ‹å™¨åˆå§‹åŒ–: Provider={self.provider}, Model={self.model_name}")
        self.logger.info(f"ğŸ”„ JSONè§£æé‡è¯•é…ç½®: æœ€å¤§é‡è¯•{self.retry_config.max_retries}æ¬¡, åŸºç¡€å»¶è¿Ÿ{self.retry_config.base_delay}ç§’")
        
        try:
            # ä¸åœ¨è¿™é‡Œåˆå§‹åŒ–ChatOpenAIæ¨¡å‹ï¼Œæ”¹ä¸ºåŠ¨æ€åˆ›å»ºä»¥æ”¯æŒæ¨¡å‹åˆ‡æ¢
            # åªåˆå§‹åŒ–è§£æå™¨
            self.issues_parser = PydanticOutputParser(pydantic_object=DocumentIssues)
            self.logger.info("âœ… é—®é¢˜æ£€æµ‹å™¨åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            self.logger.error(f"âŒ é—®é¢˜æ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            raise
    
    async def detect_issues(
        self, 
        sections: List[Dict], 
        task_id: Optional[int] = None,
        progress_callback: Optional[Callable] = None
    ) -> List[Dict]:
        """
        æ£€æµ‹æ–‡æ¡£é—®é¢˜ - ä½¿ç”¨å¼‚æ­¥æ‰¹é‡å¤„ç†
        
        Args:
            sections: æ–‡æ¡£ç« èŠ‚åˆ—è¡¨
            task_id: ä»»åŠ¡ID
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
            
        Returns:
            é—®é¢˜åˆ—è¡¨
        """
        self.logger.info(f"ğŸ” å¼€å§‹æ£€æµ‹æ–‡æ¡£é—®é¢˜ï¼Œå…± {len(sections)} ä¸ªç« èŠ‚")
        
        # è¿‡æ»¤æ‰å¤ªçŸ­çš„ç« èŠ‚
        valid_sections = [
            section for section in sections 
            if len(section.get('content', '')) >= 20
        ]
        
        if not valid_sections:
            if progress_callback:
                await progress_callback("æ²¡æœ‰æœ‰æ•ˆçš„ç« èŠ‚éœ€è¦æ£€æµ‹", 100)
            return []
        
        self.logger.info(f"ğŸ“Š å‡†å¤‡æ£€æµ‹ {len(valid_sections)} ä¸ªæœ‰æ•ˆç« èŠ‚")
        
        if progress_callback:
            await progress_callback(f"å¼€å§‹æ£€æµ‹ {len(valid_sections)} ä¸ªç« èŠ‚çš„é—®é¢˜...", 25)
        
        # åˆ›å»ºå¼‚æ­¥æ£€æµ‹ä»»åŠ¡
        async def detect_section_issues(section: Dict, index: int) -> List[Dict]:
            """å¼‚æ­¥æ£€æµ‹å•ä¸ªç« èŠ‚çš„é—®é¢˜"""
            section_title = section.get('section_title', 'æœªçŸ¥ç« èŠ‚')
            section_content = section.get('content', '')
            section_start_time = time.time()
            
            # æ›´æ–°è¿›åº¦
            progress = 25 + int((index / len(valid_sections)) * 65)
            if progress_callback:
                await progress_callback(f"æ­£åœ¨æ£€æµ‹ç« èŠ‚ {index + 1}/{len(valid_sections)}: {section_title}", progress)
            
            self.logger.debug(f"ğŸ” [{index + 1}/{len(valid_sections)}] æ£€æµ‹ç« èŠ‚: {section_title}")
            self.logger.debug(f"ğŸ“Š [{index + 1}] ç« èŠ‚ä¿¡æ¯ - æ ‡é¢˜: '{section_title}', å†…å®¹é•¿åº¦: {len(section_content)}å­—ç¬¦")
            
            try:
                # ä»æ¨¡æ¿åŠ è½½æç¤ºè¯
                self.logger.debug(f"ğŸ”§ [{index + 1}] åŠ è½½ç³»ç»Ÿæç¤ºæ¨¡æ¿")
                system_prompt = prompt_loader.get_system_prompt('document_detect_issues')
                
                # æ£€æŸ¥ç« èŠ‚å†…å®¹é•¿åº¦ï¼Œä½†ä¸æˆªå– - ç›¸ä¿¡å‰ç½®çš„åˆ†å‰²å’Œåˆå¹¶å·²ç»ä¼˜åŒ–è¿‡
                section_content_chars = len(section_content)
                context_window = self.model_config.get('config', {}).get('context_window', 8000)
                
                # è®¡ç®—ç†è®ºä¸Šä¸‹æ–‡ä½¿ç”¨é‡ï¼ˆä»…ç”¨äºæ—¥å¿—å’Œè­¦å‘Šï¼‰
                system_prompt_length = len(system_prompt) if system_prompt else 0
                format_instructions_length = len(self.issues_parser.get_format_instructions())
                reserved_length = system_prompt_length + format_instructions_length + 500
                estimated_total_chars = reserved_length + section_content_chars
                estimated_tokens = estimated_total_chars // 4  # ç²—ç•¥ä¼°ç®—
                
                self.logger.debug(f"ğŸ“ [{index + 1}] ä¸Šä¸‹æ–‡ä½¿ç”¨ - ç« èŠ‚: {section_content_chars}å­—ç¬¦, é¢„è®¡æ€»è®¡: {estimated_tokens} tokens (çª—å£: {context_window})")
                
                # å¦‚æœå†…å®¹å¾ˆé•¿ï¼Œè®°å½•è­¦å‘Šä½†ä¸æˆªå–ï¼ˆç›¸ä¿¡å‰é¢çš„åˆ†å‰²åˆå¹¶å·²ç»å¤„ç†è¿‡ï¼‰
                if estimated_tokens > context_window * 0.9:  # è¶…è¿‡90%å®¹é‡æ‰è­¦å‘Š
                    self.logger.warning(f"âš ï¸ [{index + 1}] ç« èŠ‚ '{section_title}' å†…å®¹è¾ƒé•¿({section_content_chars}å­—ç¬¦, ~{estimated_tokens} tokens)ï¼Œå¯èƒ½æ¥è¿‘æ¨¡å‹ä¸Šä¸‹æ–‡é™åˆ¶")
                    self.logger.info(f"   ğŸ’¡ ä¾èµ–å‰ç½®çš„æ–‡æ¡£åˆ†å‰²å’Œç« èŠ‚åˆå¹¶ä¼˜åŒ–ï¼Œä¸åœ¨æ­¤æ­¥éª¤æˆªå–å†…å®¹")
                
                # ä½¿ç”¨å®Œæ•´çš„ç« èŠ‚å†…å®¹ï¼Œä¸æˆªå–
                section_content_full = section_content
                
                user_prompt = prompt_loader.get_user_prompt(
                    'document_detect_issues',
                    section_title=section_title,
                    format_instructions=self.issues_parser.get_format_instructions(),
                    section_content=section_content_full
                )

                # åˆ›å»ºæ¶ˆæ¯
                messages = [
                    SystemMessage(content=system_prompt),
                    HumanMessage(content=user_prompt)
                ]
                
                # ä½¿ç”¨é‡è¯•è§£æå™¨è¿›è¡ŒAIè°ƒç”¨å’ŒJSONè§£æ
                self.logger.info(f"ğŸ“¤ è°ƒç”¨æ¨¡å‹æ£€æµ‹ç« èŠ‚ '{section_title}' (æ”¯æŒé‡è¯•)")
                
                # å®šä¹‰AIè°ƒç”¨å‡½æ•°
                async def ai_call_func():
                    return await self._call_ai_model(messages)
                
                # å®šä¹‰JSONæå–å‡½æ•°
                def json_extractor(content: str) -> Dict[str, Any]:
                    # æŸ¥æ‰¾JSONå†…å®¹
                    json_match = re.search(r'\{.*\}', content, re.DOTALL)
                    if json_match:
                        json_str = json_match.group()
                        result = json.loads(json_str)
                        # éªŒè¯ç»“æœç»“æ„
                        if 'issues' not in result:
                            result = {'issues': []}
                        return result
                    else:
                        raise ValueError("æœªæ‰¾åˆ°JSONæ ¼å¼å†…å®¹")
                
                try:
                    # ä½¿ç”¨å¸¦é‡è¯•çš„è§£æå™¨
                    result = await ai_retry_parser.parse_json_with_retry(
                        ai_call_func=ai_call_func,
                        json_extractor=json_extractor,
                        retry_config=self.retry_config,
                        operation_name=f"æ£€æµ‹ç« èŠ‚ '{section_title}'"
                    )
                    
                    processing_time = time.time() - section_start_time
                    issues = result.get('issues', [])
                    
                    self.logger.info(f"âœ… ç« èŠ‚ '{section_title}' æ£€æµ‹å®Œæˆï¼Œå‘ç° {len(issues)} ä¸ªé—®é¢˜ (è€—æ—¶: {processing_time:.2f}s)")
                    
                    # ä¿å­˜æˆåŠŸç»“æœåˆ°æ•°æ®åº“ (åªæ·»åŠ ï¼Œä¸æäº¤)
                    if self.db and task_id:
                        try:
                            # éªŒè¯task_idæ˜¯å¦æœ‰æ•ˆï¼Œé¿å…å¤–é”®çº¦æŸå¤±è´¥
                            from app.models.task import Task
                            task_exists = self.db.query(Task.id).filter(Task.id == task_id).first()
                            
                            if task_exists:
                                # ä¿æŒåŸå§‹è¾“å…¥æ–‡æœ¬å†…å®¹ï¼Œä¸è¿›è¡Œä»»ä½•ä¿®æ”¹
                                display_input_text = section_content
                                
                                ai_output = AIOutput(
                                    task_id=task_id,
                                    operation_type="detect_issues",
                                    section_title=section_title,
                                    section_index=index,
                                    input_text=display_input_text,
                                    raw_output=json.dumps(result, ensure_ascii=False),
                                    parsed_output=result,
                                    processing_time=processing_time,
                                    status="success"
                                )
                                self.db.add(ai_output)
                                # ç§»é™¤å³æ—¶æäº¤ï¼Œæ”¹ä¸ºæ‰¹é‡æäº¤
                            else:
                                self.logger.warning(f"âš ï¸ task_id {task_id} ä¸å­˜åœ¨ï¼Œè·³è¿‡AIè¾“å‡ºè®°å½•ä¿å­˜")
                        except Exception as db_error:
                            self.logger.error(f"âŒ ä¿å­˜AIè¾“å‡ºæˆåŠŸè®°å½•æ—¶å‘ç”Ÿé”™è¯¯: {db_error}")
                            # å›æ»šä»¥é¿å…å½±å“ä¸»äº‹åŠ¡
                            self.db.rollback()
                    
                    # ä¸ºæ¯ä¸ªé—®é¢˜æ·»åŠ ç« èŠ‚ä¿¡æ¯
                    for issue in issues:
                        if 'location' in issue and section_title not in issue.get('location', ''):
                            issue['location'] = f"{section_title} - {issue['location']}"
                    
                    return issues
                
                except Exception as e:
                    import traceback
                    processing_time = time.time() - section_start_time
                    self.logger.error(f"âŒ ç« èŠ‚ '{section_title}' æ£€æµ‹å¤±è´¥ (åŒ…å«é‡è¯•): {str(e)}")
                    self.logger.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
                    self.logger.debug(f"å®Œæ•´å †æ ˆ:\n{traceback.format_exc()}")
                    
                    # ä¿å­˜å¤±è´¥ç»“æœåˆ°æ•°æ®åº“
                    if self.db and task_id:
                        try:
                            # éªŒè¯task_idæ˜¯å¦æœ‰æ•ˆï¼Œé¿å…å¤–é”®çº¦æŸå¤±è´¥
                            from app.models.task import Task
                            task_exists = self.db.query(Task.id).filter(Task.id == task_id).first()
                            
                            if task_exists:
                                # ä¿æŒåŸå§‹è¾“å…¥æ–‡æœ¬å†…å®¹ï¼Œä¸è¿›è¡Œä»»ä½•ä¿®æ”¹
                                display_input_text = section_content
                                
                                ai_output = AIOutput(
                                    task_id=task_id,
                                    operation_type="detect_issues",
                                    section_title=section_title,
                                    section_index=index,
                                    input_text=display_input_text,
                                    raw_output="",
                                    processing_time=processing_time,
                                    status="failed_with_retry",
                                    error_message=str(e)
                                )
                                self.db.add(ai_output)
                                # ç§»é™¤å³æ—¶æäº¤ï¼Œæ”¹ä¸ºæ‰¹é‡æäº¤
                            else:
                                self.logger.warning(f"âš ï¸ task_id {task_id} ä¸å­˜åœ¨ï¼Œè·³è¿‡AIè¾“å‡ºè®°å½•ä¿å­˜")
                        except Exception as db_error:
                            self.logger.error(f"âŒ ä¿å­˜AIè¾“å‡ºå¤±è´¥è®°å½•æ—¶å‘ç”Ÿé”™è¯¯: {db_error}")
                            # å›æ»šä»¥é¿å…å½±å“ä¸»äº‹åŠ¡
                            self.db.rollback()
                    
                    return []
                    
            except Exception as e:
                import traceback
                self.logger.error(f"âŒ æ£€æµ‹ç« èŠ‚ '{section_title}' å¤±è´¥: {str(e)}")
                self.logger.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
                self.logger.error(f"å®Œæ•´å †æ ˆ:\n{traceback.format_exc()}")
                processing_time = time.time() - section_start_time
                
                # ä¿å­˜é”™è¯¯ä¿¡æ¯åˆ°æ•°æ®åº“
                if self.db and task_id:
                    try:
                        # éªŒè¯task_idæ˜¯å¦æœ‰æ•ˆï¼Œé¿å…å¤–é”®çº¦æŸå¤±è´¥
                        from app.models.task import Task
                        task_exists = self.db.query(Task.id).filter(Task.id == task_id).first()
                        
                        if task_exists:
                            # æ™ºèƒ½æˆªå–è¾“å…¥æ–‡æœ¬ï¼Œé¿å…åœ¨å¥å­ä¸­é—´æˆªæ–­
                            display_input_text = self._smart_truncate_text(section_content, 1000)
                            
                            ai_output = AIOutput(
                                task_id=task_id,
                                operation_type="detect_issues",
                                section_title=section_title,
                                section_index=index,
                                input_text=display_input_text,
                                raw_output="",
                                status="failed",
                                error_message=str(e),
                                processing_time=processing_time
                            )
                            self.db.add(ai_output)
                            # ç§»é™¤å³æ—¶æäº¤ï¼Œæ”¹ä¸ºæ‰¹é‡æäº¤
                        else:
                            self.logger.warning(f"âš ï¸ task_id {task_id} ä¸å­˜åœ¨ï¼Œè·³è¿‡AIè¾“å‡ºè®°å½•ä¿å­˜")
                    except Exception as db_error:
                        self.logger.error(f"âŒ ä¿å­˜AIè¾“å‡ºé”™è¯¯è®°å½•æ—¶å‘ç”Ÿé”™è¯¯: {db_error}")
                        # å›æ»šä»¥é¿å…å½±å“ä¸»äº‹åŠ¡
                        self.db.rollback()
                
                return []
        
        # æ‰¹é‡å¹¶å‘æ‰§è¡Œæ‰€æœ‰ç« èŠ‚çš„æ£€æµ‹
        self.logger.info(f"ğŸš€ å¼€å§‹å¹¶å‘æ£€æµ‹ {len(valid_sections)} ä¸ªç« èŠ‚...")
        
        # åˆ›å»ºæ‰€æœ‰æ£€æµ‹ä»»åŠ¡
        tasks = [
            detect_section_issues(section, index) 
            for index, section in enumerate(valid_sections)
        ]
        
        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # åˆå¹¶æ‰€æœ‰æ£€æµ‹ç»“æœ
        all_issues = []
        for result in results:
            if isinstance(result, list):
                all_issues.extend(result)
            elif isinstance(result, Exception):
                self.logger.warning(f"âš ï¸ æŸä¸ªç« èŠ‚æ£€æµ‹å‡ºç°å¼‚å¸¸: {str(result)}")
        
        # æ‰¹é‡æäº¤æ‰€æœ‰æ•°æ®åº“æ“ä½œï¼ˆè§£å†³é”ç«äº‰é—®é¢˜ï¼‰
        if self.db:
            try:
                commit_start = time.time()
                self.db.commit()
                commit_time = (time.time() - commit_start) * 1000
                self.logger.info(f"ğŸ“ æ‰¹é‡æäº¤AIè¾“å‡ºè®°å½•å®Œæˆï¼Œè€—æ—¶: {commit_time:.1f}ms")
            except Exception as commit_error:
                self.logger.error(f"âŒ æ‰¹é‡æäº¤AIè¾“å‡ºè®°å½•å¤±è´¥: {commit_error}")
                try:
                    self.db.rollback()
                    self.logger.info("ğŸ”„ æ•°æ®åº“å›æ»šå®Œæˆ")
                except Exception as rollback_error:
                    self.logger.error(f"âŒ æ•°æ®åº“å›æ»šå¤±è´¥: {rollback_error}")
        
        # æ›´æ–°è¿›åº¦ï¼šå®Œæˆ
        if progress_callback:
            await progress_callback(f"é—®é¢˜æ£€æµ‹å®Œæˆï¼Œå…±å‘ç° {len(all_issues)} ä¸ªé—®é¢˜", 100)
        
        self.logger.info(f"âœ… æ–‡æ¡£æ£€æµ‹å®Œæˆï¼Œå…±å‘ç° {len(all_issues)} ä¸ªé—®é¢˜")
        return all_issues
    
    def filter_issues_by_severity(self, issues: List[Dict], min_confidence: float = 0.6) -> List[Dict]:
        """
        æ ¹æ®ç½®ä¿¡åº¦è¿‡æ»¤é—®é¢˜
        
        Args:
            issues: é—®é¢˜åˆ—è¡¨
            min_confidence: æœ€å°ç½®ä¿¡åº¦é˜ˆå€¼
            
        Returns:
            è¿‡æ»¤åçš„é—®é¢˜åˆ—è¡¨
        """
        filtered_issues = []
        
        for issue in issues:
            confidence = issue.get('confidence', 0.8)
            
            # å¤„ç†éæ•°å­—ç½®ä¿¡åº¦
            try:
                confidence_float = float(confidence)
                if confidence_float >= min_confidence:
                    filtered_issues.append(issue)
                else:
                    self.logger.debug(f"è¿‡æ»¤ä½ç½®ä¿¡åº¦é—®é¢˜: {issue.get('type', 'Unknown')} (ç½®ä¿¡åº¦: {confidence})")
            except (ValueError, TypeError):
                # æ— æ•ˆçš„ç½®ä¿¡åº¦ï¼Œè·³è¿‡æ­¤é—®é¢˜
                self.logger.warning(f"è·³è¿‡æ— æ•ˆç½®ä¿¡åº¦é—®é¢˜: {issue.get('type', 'Unknown')} (ç½®ä¿¡åº¦: {confidence})")
        
        self.logger.info(f"é—®é¢˜è¿‡æ»¤å®Œæˆ: {len(issues)} -> {len(filtered_issues)} (ç½®ä¿¡åº¦ >= {min_confidence})")
        return filtered_issues
    
    def categorize_issues(self, issues: List[Dict]) -> Dict[str, List[Dict]]:
        """
        æŒ‰ä¸¥é‡ç­‰çº§åˆ†ç±»é—®é¢˜
        
        Args:
            issues: é—®é¢˜åˆ—è¡¨
            
        Returns:
            æŒ‰ä¸¥é‡ç­‰çº§åˆ†ç±»çš„é—®é¢˜å­—å…¸
        """
        categories = {
            'è‡´å‘½': [],
            'ä¸¥é‡': [],
            'ä¸€èˆ¬': [],
            'æç¤º': []
        }
        
        for issue in issues:
            severity = issue.get('severity', 'ä¸€èˆ¬')
            if severity in categories:
                categories[severity].append(issue)
            else:
                categories['ä¸€èˆ¬'].append(issue)
        
        # è®°å½•ç»Ÿè®¡ä¿¡æ¯
        for severity, severity_issues in categories.items():
            if severity_issues:
                self.logger.info(f"ğŸ“Š {severity}é—®é¢˜: {len(severity_issues)} ä¸ª")
        
        return categories
    
    async def _call_ai_model(self, messages):
        """
        è°ƒç”¨AIæ¨¡å‹ï¼ˆåŠ¨æ€åˆ›å»ºæ¨¡å‹å®ä¾‹ä»¥æ”¯æŒæ¨¡å‹åˆ‡æ¢ï¼‰
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            AIæ¨¡å‹å“åº”
        """
        # åŠ¨æ€åˆ›å»ºChatOpenAIå®ä¾‹ï¼Œç¡®ä¿ä½¿ç”¨æœ€æ–°çš„æ¨¡å‹é…ç½®
        model = ChatOpenAI(
            api_key=self.api_key,
            base_url=self.api_base,
            model=self.model_name,
            temperature=self.temperature,
            max_tokens=self.max_tokens,
            request_timeout=self.timeout,
            max_retries=self.max_retries
        )
        
        # è®°å½•å®é™…ä½¿ç”¨çš„æ¨¡å‹ä¿¡æ¯
        self.logger.debug(f"ğŸ¤– åŠ¨æ€åˆ›å»ºAIæ¨¡å‹: {self.model_name} @ {self.api_base}")
        
        # è°ƒç”¨æ¨¡å‹
        return await asyncio.to_thread(model.invoke, messages)
    
    async def analyze_document(self, text: str, prompt_type: str = "detect_issues") -> Dict[str, Any]:
        """
        ç»Ÿä¸€çš„æ–‡æ¡£åˆ†ææ¥å£ï¼Œå…¼å®¹task_processorçš„è°ƒç”¨
        
        Args:
            text: æ–‡æ¡£æ–‡æœ¬å†…å®¹
            prompt_type: æç¤ºç±»å‹ï¼Œå¯¹äºIssueDetectorä»…æ”¯æŒ"detect_issues"
            
        Returns:
            åˆ†æç»“æœ
        """
        if prompt_type != "detect_issues":
            raise ValueError(f"IssueDetectoråªæ”¯æŒdetect_issuesç±»å‹ï¼Œæ”¶åˆ°: {prompt_type}")
        
        # å°†æ–‡æœ¬è½¬æ¢ä¸ºç« èŠ‚æ ¼å¼ï¼Œä»¥ä¾¿è°ƒç”¨detect_issuesæ–¹æ³•
        sections = [{"section_title": "æ–‡æ¡£å†…å®¹", "content": text, "level": 1}]
        
        # è°ƒç”¨é—®é¢˜æ£€æµ‹æ–¹æ³•
        issues = await self.detect_issues(sections)
        
        # æ„å»ºè¿”å›æ ¼å¼ï¼Œå…¼å®¹task_processorçš„æœŸæœ›
        return {
            "status": "success",
            "data": {
                "issues": issues,
                "summary": {
                    "total_issues": len(issues),
                    "critical": sum(1 for i in issues if i.get("severity") == "è‡´å‘½"),
                    "major": sum(1 for i in issues if i.get("severity") == "ä¸¥é‡"),
                    "normal": sum(1 for i in issues if i.get("severity") == "ä¸€èˆ¬"),
                    "minor": sum(1 for i in issues if i.get("severity") == "æç¤º")
                }
            },
            "raw_output": json.dumps({"issues": issues}, ensure_ascii=False, indent=2),
            "tokens_used": 200,  # ä¼°ç®—å€¼
            "processing_time": 2.0  # ä¼°ç®—å€¼
        }