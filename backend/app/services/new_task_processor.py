"""
æ–°ä»»åŠ¡å¤„ç†å™¨ - ä½¿ç”¨è´£ä»»é“¾æ¨¡å¼
"""
import asyncio
import json
import logging
import time
from datetime import datetime
from pathlib import Path
from typing import Optional, Dict, Any
from sqlalchemy.orm import Session
from sqlalchemy.exc import SQLAlchemyError

from app.core.database import get_independent_db_session, close_independent_db_session
from app.repositories.task import TaskRepository
from app.repositories.issue import IssueRepository
from app.repositories.ai_output import AIOutputRepository
from app.repositories.file_info import FileInfoRepository
from app.repositories.ai_model import AIModelRepository
from app.core.config import get_settings
from app.services.websocket import manager
from app.models import TaskLog
from app.services.processing_chain import TaskProcessingChain
from app.services.ai_service_providers.service_provider_factory import ai_service_provider_factory


class NewTaskProcessor:
    """æ–°ä»»åŠ¡å¤„ç†å™¨ - ä½¿ç”¨è´£ä»»é“¾æ¨¡å¼ï¼Œæ”¯æŒå¹¶å‘å¼‚æ­¥å¤„ç†"""
    
    def __init__(self, db: Session = None):
        # ä¸ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„dbä¼šè¯ï¼Œè€Œæ˜¯åœ¨å¤„ç†æ—¶åˆ›å»ºæ–°çš„ä¼šè¯
        self._external_db = db  # ä¿ç•™å¼•ç”¨ï¼Œä½†ä¸ç›´æ¥ä½¿ç”¨
        self.settings = get_settings()
        self.start_time = None  # è®°å½•ä»»åŠ¡å¼€å§‹æ—¶é—´
        
        # åˆå§‹åŒ–æ—¥å¿—
        self.logger = logging.getLogger(f"new_task_processor.{id(self)}")
        self.logger.setLevel(logging.INFO)
        
    def _create_db_session(self) -> Session:
        """ä¸ºæ¯ä¸ªä»»åŠ¡å¤„ç†åˆ›å»ºç‹¬ç«‹çš„æ•°æ®åº“ä¼šè¯ï¼ˆå¸¦ç›‘æ§ï¼‰"""
        print(f"ğŸ”— ä»»åŠ¡å¤„ç†å™¨åˆ›å»ºç‹¬ç«‹æ•°æ®åº“ä¼šè¯")
        return get_independent_db_session()
        
    def _initialize_repositories(self, db: Session):
        """ä½¿ç”¨ç»™å®šçš„æ•°æ®åº“ä¼šè¯åˆå§‹åŒ–æ‰€æœ‰ä»“åº“"""
        return {
            'task_repo': TaskRepository(db),
            'issue_repo': IssueRepository(db),
            'ai_output_repo': AIOutputRepository(db),
            'file_repo': FileInfoRepository(db),
            'model_repo': AIModelRepository(db)
        }
    
    async def process_task(self, task_id: int):
        """å¤„ç†ä»»åŠ¡ï¼ˆä½¿ç”¨ç‹¬ç«‹çš„æ•°æ®åº“ä¼šè¯ï¼‰"""
        db = None
        try:
            # ä¸ºæ­¤ä»»åŠ¡åˆ›å»ºç‹¬ç«‹çš„æ•°æ®åº“ä¼šè¯
            db = self._create_db_session()
            repos = self._initialize_repositories(db)
            
            # è®°å½•ä»»åŠ¡å¼€å§‹æ—¶é—´ï¼ˆä½¿ç”¨UTCæ—¶é—´æˆ³ï¼‰
            self.start_time = time.time()
            
            # è®°å½•å¼€å§‹æ—¥å¿—
            await self._log(task_id, "INFO", "å¼€å§‹å¤„ç†ä»»åŠ¡", "åˆå§‹åŒ–", 0, db)
            
            # è·å–ä»»åŠ¡ä¿¡æ¯
            task = repos['task_repo'].get(task_id)
            if not task:
                raise ValueError(f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
            
            # æ›´æ–°çŠ¶æ€ä¸ºå¤„ç†ä¸­
            repos['task_repo'].update(task_id, status="processing", progress=10)
            await manager.send_status(task_id, "processing")
            
            # å‡†å¤‡å¤„ç†ä¸Šä¸‹æ–‡
            context = await self._prepare_context(task_id, task, repos['file_repo'], db)
            
            # è·å–ä»»åŠ¡å…³è”çš„AIæ¨¡å‹å¹¶æ‰¾åˆ°å¯¹åº”çš„ç´¢å¼•
            task_model_index = self.settings.default_model_index  # é»˜è®¤å€¼
            if task.model_id:
                # æ ¹æ®model_idæŸ¥æ‰¾æ¨¡å‹é…ç½®
                ai_model = repos['model_repo'].get_by_id(task.model_id)
                if ai_model:
                    # åœ¨settingsçš„æ¨¡å‹åˆ—è¡¨ä¸­æŸ¥æ‰¾å¯¹åº”çš„ç´¢å¼•
                    for index, model_config in enumerate(self.settings.ai_models):
                        config_model_name = model_config.get('config', {}).get('model')
                        config_provider = model_config.get('provider')
                        
                        # ä½¿ç”¨model_nameå’Œproviderè¿›è¡ŒåŒ¹é…
                        if (config_model_name == ai_model.model_name and 
                            config_provider == ai_model.provider):
                            task_model_index = index
                            self.logger.info(f"ğŸ¯ æ‰¾åˆ°ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹: {ai_model.label} (model: {ai_model.model_name}, provider: {ai_model.provider}, ç´¢å¼•: {index})")
                            break
                    else:
                        self.logger.warning(f"âš ï¸ æœªæ‰¾åˆ°åŒ¹é…çš„æ¨¡å‹é…ç½®ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹ã€‚æ¨¡å‹ä¿¡æ¯: label={ai_model.label}, model={ai_model.model_name}, provider={ai_model.provider}")
                        self.logger.info("å¯ç”¨æ¨¡å‹é…ç½®:")
                        for i, cfg in enumerate(self.settings.ai_models):
                            cfg_model = cfg.get('config', {}).get('model', 'unknown')
                            cfg_provider = cfg.get('provider', 'unknown')
                            self.logger.info(f"  [{i}] {cfg.get('label', 'unknown')} - {cfg_provider} ({cfg_model})")
                else:
                    self.logger.warning(f"âš ï¸ ä»»åŠ¡å…³è”çš„æ¨¡å‹ä¸å­˜åœ¨(model_id={task.model_id})ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹")
            
            # åˆ›å»ºAIæœåŠ¡æä¾›è€…
            ai_service_provider = ai_service_provider_factory.create_provider(
                settings=self.settings,
                model_index=task_model_index,
                db_session=db
            )
            
            # åˆ›å»ºå¤„ç†é“¾
            processing_chain = TaskProcessingChain(ai_service_provider)
            
            # æ‰§è¡Œå¤„ç†é“¾
            provider_info = ai_service_provider.get_provider_info()
            await self._log(task_id, "INFO", f"ä½¿ç”¨AIæœåŠ¡: {ai_service_provider.get_provider_name()}", "åˆå§‹åŒ–", 10, db)
            await self._log(task_id, "INFO", f"æ¨¡å‹é…ç½®: {provider_info.get('model', 'unknown')} @ {provider_info.get('provider', 'unknown')}", "åˆå§‹åŒ–", 12, db)
            
            async def progress_callback(message: str, progress: int):
                """è¿›åº¦å›è°ƒå‡½æ•°"""
                # è®°å½•æ—¥å¿—å¹¶æ¨é€æ¶ˆæ¯
                await self._log(task_id, "INFO", message, "å¤„ç†ä¸­", progress, db)
                # æ›´æ–°ä»»åŠ¡è¿›åº¦
                repos['task_repo'].update(task_id, progress=progress)
                # å‘é€è¿›åº¦çŠ¶æ€æ›´æ–°ï¼ˆä¸é‡å¤å‘é€æ¶ˆæ¯ï¼‰
                await manager.send_status(task_id, "processing")
            
            context['progress_callback'] = progress_callback
            
            # æ‰§è¡Œå®Œæ•´çš„å¤„ç†é“¾
            result = await processing_chain.execute(context, progress_callback)
            
            if not result.success:
                raise ValueError(f"ä»»åŠ¡å¤„ç†å¤±è´¥: {result.error}")
            
            # æŠ¥å‘Šç”Ÿæˆé˜¶æ®µ
            await self._log(task_id, "INFO", "å¼€å§‹ç”Ÿæˆå¤„ç†æŠ¥å‘Š", "æŠ¥å‘Šç”Ÿæˆ", 90, db)
            
            # ä¿å­˜å¤„ç†ç»“æœ
            await self._save_processing_results(task_id, context, result, repos, db)
            
            await self._log(task_id, "INFO", "å¤„ç†ç»“æœä¿å­˜å®Œæˆ", "æŠ¥å‘Šç”Ÿæˆ", 95, db)
            
            # å®Œæˆä»»åŠ¡
            # ä½¿ç”¨ä»»åŠ¡å®é™…å¼€å§‹æ—¶é—´è®¡ç®—è€—æ—¶ï¼Œé¿å…æ—¶åŒºè½¬æ¢é—®é¢˜
            processing_time = time.time() - self.start_time if self.start_time else 0
            repos['task_repo'].update(
                task_id, 
                status="completed",
                progress=100,
                processing_time=processing_time,
                completed_at=datetime.utcnow()  # ä½¿ç”¨UTCæ—¶é—´ä¿æŒä¸€è‡´æ€§
            )
            await manager.send_progress(task_id, 100, "å®Œæˆ")
            await manager.send_status(task_id, "completed")
            await self._log(task_id, "INFO", f"ä»»åŠ¡å¤„ç†å®Œæˆï¼Œè€—æ—¶{processing_time:.2f}ç§’", "å®Œæˆ", 100, db)
            
        except Exception as e:
            # è®°å½•é”™è¯¯
            if db:
                try:
                    await self._log(task_id, "ERROR", f"ä»»åŠ¡å¤„ç†å¤±è´¥: {str(e)}", "é”™è¯¯", 0, db)
                    # å¦‚æœreposå·²åˆå§‹åŒ–ï¼Œä½¿ç”¨å®ƒä»¬æ›´æ–°ä»»åŠ¡çŠ¶æ€
                    if 'repos' in locals():
                        repos['task_repo'].update(
                            task_id, 
                            status="failed", 
                            error_message=str(e)
                        )
                    else:
                        # å¦åˆ™åˆ›å»ºä¸´æ—¶ä»“åº“
                        temp_repo = TaskRepository(db)
                        temp_repo.update(
                            task_id, 
                            status="failed", 
                            error_message=str(e)
                        )
                except Exception as log_error:
                    self.logger.error(f"è®°å½•é”™è¯¯æ—¥å¿—æ—¶å¤±è´¥: {log_error}")
                    
            await manager.send_status(task_id, "failed")
            raise
        finally:
            # ç¡®ä¿æ•°æ®åº“ä¼šè¯è¢«æ­£ç¡®å…³é—­ï¼ˆå¸¦ç›‘æ§ï¼‰
            if db:
                try:
                    close_independent_db_session(db, f"ä»»åŠ¡{task_id}å¤„ç†å®Œæˆ")
                except Exception as close_error:
                    self.logger.error(f"å…³é—­æ•°æ®åº“ä¼šè¯æ—¶å‡ºé”™: {close_error}")
    
    async def _prepare_context(self, task_id: int, task, file_repo, db: Session) -> Dict[str, Any]:
        """å‡†å¤‡å¤„ç†ä¸Šä¸‹æ–‡"""
        context = {
            'task_id': task_id
        }
        
        # è·å–æ–‡ä»¶ä¿¡æ¯
        file_info = None
        if task.file_id:
            file_info = file_repo.get_by_id(task.file_id)
        
        if file_info:
            context['file_path'] = file_info.file_path
            context['file_name'] = file_info.original_name
            await self._log(task_id, "INFO", f"æ­£åœ¨å¤„ç†æ–‡æ¡£: {file_info.original_name}", "æ–‡æ¡£è§£æ", 10, db)
        else:
            context['file_name'] = "æµ‹è¯•æ–‡æ¡£"
            await self._log(task_id, "INFO", "ä½¿ç”¨æµ‹è¯•æ¨¡å¼æ–‡æ¡£", "æ–‡æ¡£è§£æ", 10, db)
        
        return context
    
    async def _save_processing_results(self, task_id: int, context: Dict[str, Any], result, repos, db: Session):
        """ä¿å­˜å¤„ç†ç»“æœ"""
        await self._log(task_id, "INFO", "æ­£åœ¨ä¿å­˜å¤„ç†ç»“æœ", "ä¿å­˜ç»“æœ", 85, db)
        
        # ä¿å­˜æ–‡ä»¶è§£æç»“æœï¼ˆéAIæ­¥éª¤ï¼Œä¿å­˜å¤„ç†è®°å½•ï¼‰
        if 'file_parsing_result' in context:
            self._save_ai_output(
                repos['ai_output_repo'],
                task_id=task_id,
                operation_type="file_parsing",
                input_text=str(context.get('file_path', 'test')),
                result={
                    'status': 'success',
                    'data': {'content': context['file_parsing_result'][:1000]},  # åªä¿å­˜å‰1000å­—ç¬¦
                    'processing_stage': 'file_parsing'
                }
            )
        
        # ç« èŠ‚åˆå¹¶ç»“æœè®°å½•ï¼ˆéAIæ­¥éª¤ï¼Œä¿å­˜å¤„ç†è®°å½•ï¼‰
        if 'section_merge_result' in context:
            original_count = len(context.get('document_processing_result', []))
            merged_count = len(context['section_merge_result'])
            self._save_ai_output(
                repos['ai_output_repo'],
                task_id=task_id,
                operation_type="section_merge",
                input_text=f"åŸå§‹ç« èŠ‚æ•°: {original_count}",
                result={
                    'status': 'success',
                    'data': {
                        'original_sections_count': original_count,
                        'merged_sections_count': merged_count,
                        'merge_ratio': merged_count / original_count if original_count > 0 else 0,
                        'merged_sections': context['section_merge_result'][:3]  # ä¿å­˜å‰3ä¸ªåˆå¹¶ç« èŠ‚çš„æ¦‚è¦
                    },
                    'processing_stage': 'section_merge'
                }
            )
        
        # ä¿å­˜é—®é¢˜åˆ°æ•°æ®åº“ï¼ˆé—®é¢˜æ£€æµ‹çš„AIè¾“å‡ºå·²ç”±IssueDetectorä¿å­˜ï¼‰
        if 'issue_detection_result' in context:
            issues = context['issue_detection_result']
            
            # ä¿å­˜é—®é¢˜åˆ°æ•°æ®åº“
            issue_count = len(issues) if issues else 0
            await self._log(task_id, "INFO", f"æ£€æµ‹åˆ°{issue_count}ä¸ªé—®é¢˜", "ä¿å­˜ç»“æœ", 90, db)
            
            for issue in (issues or []):
                repos['issue_repo'].create(
                    task_id=task_id,
                    issue_type=issue.get('type', 'æœªçŸ¥'),  # ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„å­—æ®µå 'type'
                    description=issue.get('description', ''),
                    location=issue.get('location', ''),
                    severity=issue.get('severity', 'ä¸€èˆ¬'),
                    confidence=issue.get('confidence'),
                    suggestion=issue.get('suggestion', ''),
                    original_text=issue.get('original_text'),
                    user_impact=issue.get('user_impact'),
                    reasoning=issue.get('reasoning'),
                    context=issue.get('context')
                )
    
    def _save_ai_output(self, ai_output_repo, task_id: int, operation_type: str, 
                       input_text: str, result: Dict[str, Any]):
        """ä¿å­˜AIè¾“å‡ºç»“æœ"""
        ai_output_repo.create(
            task_id=task_id,
            operation_type=operation_type,
            input_text=input_text,
            raw_output=result.get('raw_output', json.dumps(result)),
            parsed_output=result.get('data'),
            status=result.get('status', 'success'),
            error_message=result.get('error_message'),
            tokens_used=result.get('tokens_used'),
            processing_time=result.get('processing_time')
        )
    
    async def _log(self, task_id: int, level: str, message: str, stage: str = None, progress: int = None, db: Session = None):
        """è®°å½•æ—¥å¿—å¹¶å®æ—¶æ¨é€"""
        # è¿‡æ»¤ç©ºæ¶ˆæ¯ï¼Œé¿å…äº§ç”Ÿæ— ç”¨çš„æ—¥å¿—è®°å½•
        if not message or not str(message).strip():
            return
            
        # ä¿å­˜åˆ°æ•°æ®åº“
        if db:
            try:
                # éªŒè¯task_idæ˜¯å¦æœ‰æ•ˆï¼Œé¿å…å¤–é”®çº¦æŸå¤±è´¥
                from app.models.task import Task
                task_exists = db.query(Task.id).filter(Task.id == task_id).first()
                
                if task_exists:
                    log = TaskLog(
                        task_id=task_id,
                        level=level,
                        message=str(message).strip(),
                        stage=stage,
                        progress=progress
                    )
                    db.add(log)
                    db.commit()
                else:
                    self.logger.warning(f"âš ï¸ task_id {task_id} ä¸å­˜åœ¨ï¼Œè·³è¿‡ä»»åŠ¡æ—¥å¿—ä¿å­˜")
            except Exception as e:
                self.logger.error(f"ä¿å­˜æ—¥å¿—åˆ°æ•°æ®åº“æ—¶å¤±è´¥: {e}")
                # å›æ»šä»¥é¿å…å½±å“ä¸»äº‹åŠ¡
                db.rollback()
        
        # å®æ—¶æ¨é€
        try:
            await manager.send_log(task_id, level, message, stage, progress)
        except Exception as e:
            self.logger.error(f"æ¨é€æ—¥å¿—æ¶ˆæ¯æ—¶å¤±è´¥: {e}")