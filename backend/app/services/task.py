"""
ä»»åŠ¡ä¸šåŠ¡é€»è¾‘å±‚
"""
import os
import hashlib
import time
from typing import List, Optional
from sqlalchemy.orm import Session
from fastapi import UploadFile, HTTPException
import asyncio

from app.repositories.task import TaskRepository
from app.repositories.issue import IssueRepository
from app.repositories.ai_output import AIOutputRepository
from app.repositories.file_info import FileInfoRepository
from app.repositories.ai_model import AIModelRepository
from app.repositories.user import UserRepository
from app.dto.task import TaskResponse, TaskDetail
from app.dto.issue import IssueResponse
from app.dto.pagination import PaginationParams, PaginatedResponse
from app.core.config import get_settings
from app.services.interfaces.task_service import ITaskService
from datetime import datetime


class TaskService(ITaskService):
    """ä»»åŠ¡æœåŠ¡"""
    
    def __init__(self, db: Session):
        self.db = db
        self.task_repo = TaskRepository(db)
        self.issue_repo = IssueRepository(db)
        self.ai_output_repo = AIOutputRepository(db)
        self.file_repo = FileInfoRepository(db)
        self.model_repo = AIModelRepository(db)
        self.user_repo = UserRepository(db)
        self.settings = get_settings()
    
    async def create_task(self, file: UploadFile, title: Optional[str] = None, model_index: Optional[int] = None, user_id: Optional[int] = None) -> TaskResponse:
        """åˆ›å»ºä»»åŠ¡"""
        # éªŒè¯æ–‡ä»¶
        file_settings = self.settings.file_settings
        allowed_exts = ['.' + ext for ext in file_settings.get('allowed_extensions', ['pdf', 'docx', 'md'])]
        file_ext = os.path.splitext(file.filename)[1].lower()
        if file_ext not in allowed_exts:
            raise HTTPException(400, f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_ext}")
        
        # è¯»å–æ–‡ä»¶å†…å®¹
        content = await file.read()
        file_size = len(content)
        max_size = file_settings.get('max_file_size', 10485760)
        if file_size > max_size:
            raise HTTPException(400, f"æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶: {file_size / 1024 / 1024:.2f}MB")
        
        # è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
        content_hash = hashlib.sha256(content).hexdigest()
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        existing_file = self.file_repo.get_by_hash(content_hash)
        if existing_file:
            # æ–‡ä»¶å·²å­˜åœ¨ï¼Œå¤ç”¨æ–‡ä»¶è®°å½•
            file_info = existing_file
        else:
            # ä¿å­˜æ–°æ–‡ä»¶
            file_name = file.filename
            upload_dir = self.settings.upload_dir
            os.makedirs(upload_dir, exist_ok=True)
            
            # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
            timestamp = datetime.now().timestamp()
            stored_name = f"{timestamp}_{file_name}"
            file_path = os.path.join(upload_dir, stored_name)
            
            with open(file_path, 'wb') as f:
                f.write(content)
            
            # åˆ›å»ºæ–‡ä»¶ä¿¡æ¯è®°å½•
            file_info = self.file_repo.create(
                original_name=file_name,
                stored_name=stored_name,
                file_path=file_path,
                file_size=file_size,
                file_type=file_ext[1:],
                mime_type=file.content_type or 'application/octet-stream',
                content_hash=content_hash,
                encoding='utf-8',  # é»˜è®¤ç¼–ç ï¼Œå®é™…åº”è¯¥æ£€æµ‹
                is_processed='pending'
            )
        
        # è·å–AIæ¨¡å‹
        if model_index is not None:
            # ä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹ç´¢å¼•
            active_models = self.model_repo.get_active_models()
            print(f"ğŸ¯ ç”¨æˆ·é€‰æ‹©æ¨¡å‹ç´¢å¼•: {model_index}, å¯ç”¨æ¨¡å‹æ•°é‡: {len(active_models)}")
            if model_index < len(active_models):
                ai_model = active_models[model_index]
                print(f"âœ… ä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹: {ai_model.label}")
            else:
                # ç´¢å¼•è¶…å‡ºèŒƒå›´ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹
                ai_model = self.model_repo.get_default_model()
                print(f"âš ï¸ æ¨¡å‹ç´¢å¼•è¶…å‡ºèŒƒå›´ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹: {ai_model.label if ai_model else 'None'}")
        else:
            # ä½¿ç”¨é»˜è®¤æ¨¡å‹
            ai_model = self.model_repo.get_default_model()
            print(f"ğŸ”§ æœªæŒ‡å®šæ¨¡å‹ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹: {ai_model.label if ai_model else 'None'}")
        
        if not ai_model:
            raise HTTPException(400, "æ²¡æœ‰å¯ç”¨çš„AIæ¨¡å‹")
        
        # åˆ›å»ºä»»åŠ¡è®°å½•
        task = self.task_repo.create(
            title=title or os.path.splitext(file.filename)[0],
            status='pending',
            progress=0,
            user_id=user_id,
            file_id=file_info.id,
            model_id=ai_model.id
        )
        
        # å¼‚æ­¥å¤„ç†ä»»åŠ¡ - ä½¿ç”¨ä¼˜åŒ–çš„å¹¶å‘å®‰å…¨å¤„ç†å™¨
        try:
            from app.services.new_task_processor import NewTaskProcessor
            # ä¸ä¼ é€’æ•°æ®åº“ä¼šè¯ï¼Œè®©å¤„ç†å™¨è‡ªå·±åˆ›å»ºç‹¬ç«‹çš„ä¼šè¯
            processor = NewTaskProcessor()
            
            # æ£€æŸ¥å½“å‰æ˜¯å¦åœ¨å¼‚æ­¥ç¯å¢ƒä¸­
            try:
                # å°è¯•è·å–å½“å‰äº‹ä»¶å¾ªç¯
                loop = asyncio.get_running_loop()
                # åœ¨ç‹¬ç«‹çš„ä»»åŠ¡ä¸­å¤„ç†ï¼Œé¿å…é˜»å¡ä¸»çº¿ç¨‹
                task_future = asyncio.create_task(
                    self._safe_process_task(processor, task.id)
                )
                print(f"âœ… åå°ä»»åŠ¡å·²å¯åŠ¨ï¼Œä»»åŠ¡ID: {task.id}")
            except RuntimeError:
                # æ²¡æœ‰è¿è¡Œçš„äº‹ä»¶å¾ªç¯ï¼Œåœ¨æµ‹è¯•ç¯å¢ƒæˆ–åŒæ­¥ç¯å¢ƒä¸­æ˜¯æ­£å¸¸çš„
                print(f"âš ï¸ æ— æ³•å¯åŠ¨åå°ä»»åŠ¡ï¼ˆéå¼‚æ­¥ç¯å¢ƒï¼‰ï¼Œä»»åŠ¡ID: {task.id}")
                print(f"ğŸ“ ä»»åŠ¡å·²åˆ›å»ºï¼Œç­‰å¾…å¼‚æ­¥ç¯å¢ƒå¤„ç†")
                
        except Exception as e:
            print(f"âŒ å¯åŠ¨åå°ä»»åŠ¡æ—¶å‡ºé”™: {e}")
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œè®©ä»»åŠ¡åˆ›å»ºæˆåŠŸï¼Œåªæ˜¯å¤„ç†ä¼šå»¶å
        
        # è·å–å…³è”æ•°æ®æ„å»ºå“åº”
        file_info = self.file_repo.get_by_id(task.file_id) if task.file_id else None
        ai_model = self.model_repo.get_by_id(task.model_id) if task.model_id else None
        user_info = self.user_repo.get_by_id(task.user_id) if task.user_id else None
        issue_count = self.task_repo.count_issues(task.id)
        processed_issues = self.task_repo.count_processed_issues(task.id)
        return TaskResponse.from_task_with_relations(task, file_info, ai_model, user_info, issue_count, processed_issues)
    
    async def _safe_process_task(self, processor, task_id: int):
        """å®‰å…¨çš„ä»»åŠ¡å¤„ç†åŒ…è£…å™¨ï¼Œå¤„ç†å¼‚å¸¸å’Œé”™è¯¯æ¢å¤"""
        try:
            await processor.process_task(task_id)
        except Exception as e:
            print(f"âŒ ä»»åŠ¡ {task_id} å¤„ç†å¤±è´¥: {e}")
            # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤šçš„é”™è¯¯æ¢å¤é€»è¾‘ï¼Œæ¯”å¦‚é‡è¯•æœºåˆ¶
            # æˆ–è€…å‘é€é”™è¯¯é€šçŸ¥ç­‰
            
    async def batch_create_tasks(self, files_data: List[dict], user_id: Optional[int] = None, max_concurrent: int = 5) -> List[TaskResponse]:
        """æ‰¹é‡å¹¶å‘åˆ›å»ºä»»åŠ¡
        
        Args:
            files_data: æ–‡ä»¶æ•°æ®åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«file, title, model_indexç­‰
            user_id: ç”¨æˆ·ID
            max_concurrent: æœ€å¤§å¹¶å‘æ•°ï¼Œé»˜è®¤5ä¸ª
            
        Returns:
            List[TaskResponse]: åˆ›å»ºçš„ä»»åŠ¡åˆ—è¡¨
        """
        print(f"ğŸš€ å¼€å§‹æ‰¹é‡åˆ›å»º {len(files_data)} ä¸ªä»»åŠ¡ï¼Œæœ€å¤§å¹¶å‘æ•°: {max_concurrent}")
        
        # ä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘æ•°
        semaphore = asyncio.Semaphore(max_concurrent)
        
        async def create_single_task(file_data: dict) -> TaskResponse:
            """åˆ›å»ºå•ä¸ªä»»åŠ¡ï¼ˆä½¿ç”¨ç‹¬ç«‹æ•°æ®åº“ä¼šè¯ï¼Œé¿å…é”ç«äº‰ï¼‰"""
            async with semaphore:
                from app.core.database import get_independent_db_session
                # ä½¿ç”¨ç‹¬ç«‹ä¼šè¯å‡½æ•°ï¼ŒåŒ…å«SQLiteä¼˜åŒ–è®¾ç½®
                db_session = get_independent_db_session()
                try:
                    # åˆ›å»ºç‹¬ç«‹çš„TaskServiceå®ä¾‹
                    task_service = TaskService(db_session)
                    result = await task_service.create_task(
                        file=file_data.get('file'),
                        title=file_data.get('title'),
                        model_index=file_data.get('model_index'),
                        user_id=user_id
                    )
                    return result
                except Exception as e:
                    print(f"âŒ åˆ›å»ºä»»åŠ¡å¤±è´¥: {e}")
                    # å‘ç”Ÿå¼‚å¸¸æ—¶å›æ»šäº‹åŠ¡
                    try:
                        db_session.rollback()
                    except:
                        pass
                    raise
                finally:
                    # ç¡®ä¿æ•°æ®åº“ä¼šè¯æ­£ç¡®å…³é—­
                    try:
                        db_session.close()
                    except:
                        pass
        
        # å¹¶å‘åˆ›å»ºæ‰€æœ‰ä»»åŠ¡
        start_time = time.time()
        tasks = await asyncio.gather(
            *[create_single_task(file_data) for file_data in files_data],
            return_exceptions=True
        )
        
        # å¤„ç†ç»“æœ
        successful_tasks = []
        failed_tasks = []
        
        for i, result in enumerate(tasks):
            if isinstance(result, Exception):
                failed_tasks.append({
                    'index': i,
                    'file': files_data[i].get('file', {}).get('filename', 'unknown'),
                    'error': str(result)
                })
            else:
                successful_tasks.append(result)
        
        total_time = time.time() - start_time
        print(f"âœ… æ‰¹é‡åˆ›å»ºå®Œæˆï¼Œè€—æ—¶: {total_time:.2f}s")
        print(f"   æˆåŠŸ: {len(successful_tasks)} ä¸ª")
        print(f"   å¤±è´¥: {len(failed_tasks)} ä¸ª")
        
        if failed_tasks:
            print("âŒ å¤±è´¥çš„ä»»åŠ¡:")
            for failed in failed_tasks:
                print(f"   - {failed['file']}: {failed['error']}")
        
        return successful_tasks
    
    def get_all_tasks(self) -> List[TaskResponse]:
        """è·å–æ‰€æœ‰ä»»åŠ¡ï¼ˆæ€§èƒ½ä¼˜åŒ–ç‰ˆï¼‰"""
        print("ğŸš€ å¼€å§‹è·å–ä»»åŠ¡åˆ—è¡¨ï¼ˆä½¿ç”¨æ€§èƒ½ä¼˜åŒ–æŸ¥è¯¢ï¼‰...")
        start_time = time.time()
        
        # 1. ä½¿ç”¨JOINé¢„åŠ è½½å…³è”æ•°æ®ï¼Œé¿å…N+1æŸ¥è¯¢
        tasks = self.task_repo.get_all_with_relations()
        print(f"ğŸ“Š æŸ¥è¯¢åˆ° {len(tasks)} ä¸ªä»»åŠ¡ï¼Œè€—æ—¶: {(time.time() - start_time)*1000:.1f}ms")
        
        if not tasks:
            return []
        
        # 2. æ‰¹é‡ç»Ÿè®¡é—®é¢˜æ•°é‡ï¼Œé¿å…é€ä¸ªæŸ¥è¯¢
        batch_start = time.time()
        task_ids = [task.id for task in tasks]
        issue_stats = self.task_repo.batch_count_issues(task_ids)
        print(f"ğŸ“Š æ‰¹é‡ç»Ÿè®¡é—®é¢˜æ•°é‡ï¼Œè€—æ—¶: {(time.time() - batch_start)*1000:.1f}ms")
        
        # 3. æ„å»ºå“åº”å¯¹è±¡
        result = []
        for task in tasks:
            # å…³è”æ•°æ®å·²é¢„åŠ è½½ï¼Œæ— éœ€é¢å¤–æŸ¥è¯¢
            file_info = task.file_info
            ai_model = task.ai_model  
            user_info = task.user
            
            # ä»æ‰¹é‡ç»Ÿè®¡ç»“æœä¸­è·å–é—®é¢˜æ•°é‡
            stats = issue_stats.get(task.id, {"issue_count": 0, "processed_issues": 0})
            issue_count = stats["issue_count"]
            processed_issues = stats["processed_issues"]
            
            task_resp = TaskResponse.from_task_with_relations(
                task, file_info, ai_model, user_info, issue_count, processed_issues
            )
            result.append(task_resp)
        
        total_time = time.time() - start_time
        print(f"âœ… ä»»åŠ¡åˆ—è¡¨è·å–å®Œæˆï¼Œæ€»è€—æ—¶: {total_time*1000:.1f}ms")
        return result
    
    def get_paginated_tasks(self, params: PaginationParams, user_id: Optional[int] = None) -> PaginatedResponse[TaskResponse]:
        """åˆ†é¡µè·å–ä»»åŠ¡åˆ—è¡¨ï¼ˆé«˜æ€§èƒ½ç‰ˆï¼‰"""
        print(f"ğŸš€ å¼€å§‹åˆ†é¡µè·å–ä»»åŠ¡åˆ—è¡¨: page={params.page}, size={params.page_size}, user_id={user_id}")
        start_time = time.time()
        
        # æ£€æŸ¥æ•°æ®åº“ä¼šè¯çŠ¶æ€
        if not self.db.is_active:
            print("âš ï¸ æ•°æ®åº“ä¼šè¯å·²å¤±æ•ˆï¼Œé‡æ–°è·å–")
            from app.core.database import SessionLocal
            self.db = SessionLocal()
            # é‡æ–°åˆå§‹åŒ–æ‰€æœ‰ä»“åº“
            self.task_repo = TaskRepository(self.db)
            self.issue_repo = IssueRepository(self.db)
            self.ai_output_repo = AIOutputRepository(self.db)
            self.file_repo = FileInfoRepository(self.db)
            self.model_repo = AIModelRepository(self.db)
            self.user_repo = UserRepository(self.db)
        
        try:
            # 1. åˆ†é¡µæŸ¥è¯¢ä»»åŠ¡ï¼ˆè®¾ç½®æŸ¥è¯¢è¶…æ—¶ï¼‰
            query_start = time.time()
            tasks, total = self.task_repo.get_paginated_tasks(params, user_id)
            query_time = (time.time() - query_start) * 1000
            print(f"ğŸ“Š åˆ†é¡µæŸ¥è¯¢å®Œæˆ: {len(tasks)}/{total} ä»»åŠ¡ï¼Œè€—æ—¶: {query_time:.1f}ms")
            
            # å¦‚æœæŸ¥è¯¢æ—¶é—´è¿‡é•¿ï¼Œè®°å½•è­¦å‘Š
            if query_time > 5000:  # 5ç§’
                print(f"âš ï¸ åˆ†é¡µæŸ¥è¯¢è€—æ—¶å¼‚å¸¸: {query_time:.1f}msï¼Œå¯èƒ½å­˜åœ¨æ•°æ®åº“é”ç«äº‰")
            
            if not tasks:
                return PaginatedResponse.create([], total, params.page, params.page_size)
            
            # 2. æ‰¹é‡ç»Ÿè®¡é—®é¢˜æ•°é‡ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
            batch_start = time.time()
            task_ids = [task.id for task in tasks]
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å¤§é‡æœªå®Œæˆçš„ä»»åŠ¡ï¼ˆå¯èƒ½å½±å“é—®é¢˜ç»Ÿè®¡æ€§èƒ½ï¼‰
            pending_processing_count = sum(1 for task in tasks if task.status in ['pending', 'processing'])
            if pending_processing_count > 5:
                print(f"âš ï¸ æ£€æµ‹åˆ° {pending_processing_count} ä¸ªæ­£åœ¨å¤„ç†çš„ä»»åŠ¡ï¼Œå¯èƒ½å½±å“æŸ¥è¯¢æ€§èƒ½")
            
            issue_stats = self.task_repo.batch_count_issues(task_ids)
            batch_time = (time.time() - batch_start) * 1000
            print(f"ğŸ“Š æ‰¹é‡ç»Ÿè®¡é—®é¢˜æ•°é‡ï¼Œè€—æ—¶: {batch_time:.1f}ms")
            
            # 3. æ„å»ºå“åº”å¯¹è±¡
            response_start = time.time()
            result = []
            for task in tasks:
                # å…³è”æ•°æ®å·²é¢„åŠ è½½ï¼Œæ— éœ€é¢å¤–æŸ¥è¯¢
                file_info = task.file_info
                ai_model = task.ai_model
                user_info = task.user
                
                # ä»æ‰¹é‡ç»Ÿè®¡ç»“æœä¸­è·å–é—®é¢˜æ•°é‡
                issue_stat = issue_stats.get(task.id, {"issue_count": 0, "processed_issues": 0})
                
                # ä½¿ç”¨from_task_with_relationsæ–¹æ³•ç¡®ä¿æ‰€æœ‰å­—æ®µæ­£ç¡®è®¾ç½®
                task_resp = TaskResponse.from_task_with_relations(
                    task, file_info, ai_model, user_info, 
                    issue_stat["issue_count"], issue_stat["processed_issues"]
                )
                result.append(task_resp)
            
            response_time = (time.time() - response_start) * 1000
            total_time = (time.time() - start_time) * 1000
            print(f"ğŸ“„ å“åº”æ„å»ºè€—æ—¶: {response_time:.1f}ms")
            print(f"âœ… åˆ†é¡µä»»åŠ¡è·å–å®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.1f}ms")
            
            # å¦‚æœæ€»è€—æ—¶è¶…è¿‡10ç§’ï¼Œè®°å½•è¯¦ç»†æ€§èƒ½ä¿¡æ¯
            if total_time > 10000:
                print(f"ğŸš¨ åˆ†é¡µæŸ¥è¯¢æ€§èƒ½è­¦å‘Šï¼šæ€»è€—æ—¶ {total_time:.1f}ms")
                print(f"   - æŸ¥è¯¢è€—æ—¶: {query_time:.1f}ms")
                print(f"   - ç»Ÿè®¡è€—æ—¶: {batch_time:.1f}ms") 
                print(f"   - æ„å»ºè€—æ—¶: {response_time:.1f}ms")
                print(f"   - ä»»åŠ¡æ•°é‡: {len(tasks)}")
                print(f"   - å¤„ç†ä¸­ä»»åŠ¡: {pending_processing_count}")
            
            return PaginatedResponse.create(result, total, params.page, params.page_size)
            
        except Exception as e:
            total_time = (time.time() - start_time) * 1000
            print(f"âŒ åˆ†é¡µæŸ¥è¯¢å¼‚å¸¸ï¼Œè€—æ—¶: {total_time:.1f}msï¼Œé”™è¯¯: {e}")
            raise
    
    def get_all(self) -> List[TaskResponse]:
        """è·å–æ‰€æœ‰ä»»åŠ¡ï¼ˆåŸºç¡€æ¥å£æ–¹æ³•ï¼‰"""
        return self.get_all_tasks()
    
    def get_user_tasks(self, user_id: int) -> List[TaskResponse]:
        """è·å–æŒ‡å®šç”¨æˆ·çš„ä»»åŠ¡ï¼ˆæ€§èƒ½ä¼˜åŒ–ç‰ˆï¼‰"""
        print(f"ğŸš€ å¼€å§‹è·å–ç”¨æˆ· {user_id} çš„ä»»åŠ¡åˆ—è¡¨ï¼ˆä½¿ç”¨æ€§èƒ½ä¼˜åŒ–æŸ¥è¯¢ï¼‰...")
        start_time = time.time()
        
        # 1. ä½¿ç”¨JOINé¢„åŠ è½½å…³è”æ•°æ®ï¼Œé¿å…N+1æŸ¥è¯¢
        tasks = self.task_repo.get_by_user_id_with_relations(user_id)
        print(f"ğŸ“Š æŸ¥è¯¢åˆ°ç”¨æˆ· {user_id} çš„ {len(tasks)} ä¸ªä»»åŠ¡ï¼Œè€—æ—¶: {(time.time() - start_time)*1000:.1f}ms")
        
        if not tasks:
            return []
        
        # 2. æ‰¹é‡ç»Ÿè®¡é—®é¢˜æ•°é‡ï¼Œé¿å…é€ä¸ªæŸ¥è¯¢
        batch_start = time.time()
        task_ids = [task.id for task in tasks]
        issue_stats = self.task_repo.batch_count_issues(task_ids)
        print(f"ğŸ“Š æ‰¹é‡ç»Ÿè®¡é—®é¢˜æ•°é‡ï¼Œè€—æ—¶: {(time.time() - batch_start)*1000:.1f}ms")
        
        # 3. æ„å»ºå“åº”å¯¹è±¡
        result = []
        for task in tasks:
            # å…³è”æ•°æ®å·²é¢„åŠ è½½ï¼Œæ— éœ€é¢å¤–æŸ¥è¯¢
            file_info = task.file_info
            ai_model = task.ai_model
            user_info = task.user
            
            # ä»æ‰¹é‡ç»Ÿè®¡ç»“æœä¸­è·å–é—®é¢˜æ•°é‡
            stats = issue_stats.get(task.id, {"issue_count": 0, "processed_issues": 0})
            issue_count = stats["issue_count"]
            processed_issues = stats["processed_issues"]
            
            task_resp = TaskResponse.from_task_with_relations(
                task, file_info, ai_model, user_info, issue_count, processed_issues
            )
            result.append(task_resp)
        
        total_time = time.time() - start_time
        print(f"âœ… ç”¨æˆ·ä»»åŠ¡åˆ—è¡¨è·å–å®Œæˆï¼Œæ€»è€—æ—¶: {total_time*1000:.1f}ms")
        return result
    
    def get_task_detail(self, task_id: int) -> TaskDetail:
        """è·å–ä»»åŠ¡è¯¦æƒ…ï¼ˆæ‡’åŠ è½½æ¨¡å¼ï¼Œä¸åŒ…å«é—®é¢˜åˆ—è¡¨ï¼‰"""
        print(f"ğŸš€ å¼€å§‹è·å–ä»»åŠ¡è¯¦æƒ…: {task_id}ï¼ˆæ‡’åŠ è½½æ¨¡å¼ï¼‰...")
        start_time = time.time()
        
        # 1. ä½¿ç”¨JOINæŸ¥è¯¢é¢„åŠ è½½å…³è”æ•°æ®ï¼Œé¿å…N+1æŸ¥è¯¢
        task = self.task_repo.get_by_id_with_relations(task_id)
        print(f"ğŸ“Š ä»»åŠ¡æŸ¥è¯¢è€—æ—¶: {(time.time() - start_time)*1000:.1f}ms")
        
        if not task:
            print(f"âŒ ä»»åŠ¡ {task_id} ä¸å­˜åœ¨")
            raise HTTPException(404, "ä»»åŠ¡ä¸å­˜åœ¨")
        
        # 2. è·å–é—®é¢˜ç»Ÿè®¡æ‘˜è¦è€Œéå®Œæ•´é—®é¢˜åˆ—è¡¨
        stats_start = time.time()
        
        # ç»Ÿè®¡æ€»é—®é¢˜æ•°å’Œå·²å¤„ç†é—®é¢˜æ•°
        total_issues = self.task_repo.count_issues(task_id)
        processed_issues = self.task_repo.count_processed_issues(task_id)
        
        # æŒ‰ä¸¥é‡ç¨‹åº¦ç»Ÿè®¡
        from sqlalchemy import func
        from app.models import Issue
        severity_stats = dict(self.db.query(Issue.severity, func.count(Issue.id))
                            .filter(Issue.task_id == task_id)
                            .group_by(Issue.severity).all())
        
        # æŒ‰é—®é¢˜ç±»å‹ç»Ÿè®¡
        type_stats = dict(self.db.query(Issue.issue_type, func.count(Issue.id))
                         .filter(Issue.task_id == task_id)
                         .group_by(Issue.issue_type).all())
        
        # æŒ‰åé¦ˆçŠ¶æ€ç»Ÿè®¡
        feedback_stats = {
            'processed': processed_issues,
            'unprocessed': total_issues - processed_issues,
            'accept': self.db.query(Issue).filter(Issue.task_id == task_id, Issue.feedback_type == 'accept').count(),
            'reject': self.db.query(Issue).filter(Issue.task_id == task_id, Issue.feedback_type == 'reject').count(),
        }
        
        issue_summary = {
            'total': total_issues,
            'processed': processed_issues,
            'unprocessed': total_issues - processed_issues,
            'by_severity': severity_stats,
            'by_type': type_stats,
            'by_feedback': feedback_stats,
        }
        
        print(f"ğŸ“Š é—®é¢˜ç»Ÿè®¡è€—æ—¶: {(time.time() - stats_start)*1000:.1f}ms")
        
        # 3. ç»Ÿè®¡AIè¾“å‡ºæ•°é‡
        ai_outputs_start = time.time()
        
        from app.models import AIOutput
        total_ai_outputs = self.db.query(AIOutput).filter(AIOutput.task_id == task_id).count()
        successful_ai_outputs = self.db.query(AIOutput).filter(
            AIOutput.task_id == task_id,
            AIOutput.status == 'success'
        ).count()
        
        ai_output_summary = {
            'total': total_ai_outputs,
            'successful': successful_ai_outputs,
            'failed': total_ai_outputs - successful_ai_outputs
        }
        
        print(f"ğŸ“Š AIè¾“å‡ºç»Ÿè®¡è€—æ—¶: {(time.time() - ai_outputs_start)*1000:.1f}ms")
        
        # 4. å…³è”æ•°æ®å·²é¢„åŠ è½½ï¼Œæ— éœ€é¢å¤–æŸ¥è¯¢
        file_info = task.file_info
        ai_model = task.ai_model  
        user_info = task.user
        
        task_resp = TaskResponse.from_task_with_relations(
            task, file_info, ai_model, user_info, total_issues, processed_issues
        )
        
        total_time = time.time() - start_time
        print(f"âœ… ä»»åŠ¡è¯¦æƒ…è·å–å®Œæˆï¼ˆæ‡’åŠ è½½ï¼‰ï¼Œæ€»è€—æ—¶: {total_time*1000:.1f}ms")
        
        return TaskDetail(
            task=task_resp,
            issue_summary=issue_summary,
            ai_output_summary=ai_output_summary
        )
    
    def get_task_issues_paginated(self, task_id: int, params: PaginationParams) -> PaginatedResponse['IssueResponse']:
        """åˆ†é¡µè·å–ä»»åŠ¡çš„é—®é¢˜åˆ—è¡¨"""
        print(f"ğŸš€ å¼€å§‹åˆ†é¡µè·å–ä»»åŠ¡ {task_id} çš„é—®é¢˜: page={params.page}, size={params.page_size}")
        start_time = time.time()
        
        # éªŒè¯ä»»åŠ¡æ˜¯å¦å­˜åœ¨
        task = self.task_repo.get_by_id(task_id)
        if not task:
            raise HTTPException(404, "ä»»åŠ¡ä¸å­˜åœ¨")
        
        # åˆ†é¡µæŸ¥è¯¢é—®é¢˜
        issues, total = self.issue_repo.get_paginated_issues_by_task_id(task_id, params)
        
        # è½¬æ¢ä¸ºå“åº”å¯¹è±¡
        issue_responses = [IssueResponse.model_validate(issue) for issue in issues]
        
        total_time = time.time() - start_time
        print(f"âœ… é—®é¢˜åˆ†é¡µæŸ¥è¯¢å®Œæˆ: {len(issue_responses)}/{total}ï¼Œè€—æ—¶: {total_time*1000:.1f}ms")
        
        return PaginatedResponse.create(issue_responses, total, params.page, params.page_size)
    
    def delete(self, entity_id: int) -> bool:
        """åˆ é™¤ä»»åŠ¡ï¼ˆåŸºç¡€æ¥å£æ–¹æ³•ï¼‰"""
        return self.delete_task(entity_id)
    
    def delete_task(self, task_id: int) -> bool:
        """åˆ é™¤ä»»åŠ¡"""
        task = self.task_repo.get_by_id(task_id)
        if not task:
            raise HTTPException(404, "ä»»åŠ¡ä¸å­˜åœ¨")
        
        # è·å–å…³è”çš„æ–‡ä»¶ä¿¡æ¯ï¼ˆåœ¨åˆ é™¤ä»»åŠ¡ä¹‹å‰ï¼‰
        file_info = None
        if hasattr(task, 'file_id') and task.file_id:
            file_info = self.file_repo.get_by_id(task.file_id)
        
        # å…ˆåˆ é™¤ä»»åŠ¡ï¼ˆè¿™ä¼šåˆ é™¤ç›¸å…³çš„é—®é¢˜å’ŒAIè¾“å‡ºï¼‰
        task_deleted = self.task_repo.delete(task_id)
        
        # å¦‚æœä»»åŠ¡åˆ é™¤æˆåŠŸä¸”æœ‰å…³è”æ–‡ä»¶ï¼Œæ£€æŸ¥æ˜¯å¦å¯ä»¥åˆ é™¤æ–‡ä»¶
        if task_deleted and file_info:
            # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰å…¶ä»–ä»»åŠ¡ä½¿ç”¨è¿™ä¸ªæ–‡ä»¶
            from app.models import Task
            other_tasks_count = self.db.query(Task).filter(Task.file_id == file_info.id).count()
            
            # å¦‚æœæ²¡æœ‰å…¶ä»–ä»»åŠ¡ä½¿ç”¨è¿™ä¸ªæ–‡ä»¶ï¼Œåˆ™åˆ é™¤æ–‡ä»¶
            if other_tasks_count == 0:
                if os.path.exists(file_info.file_path):
                    os.remove(file_info.file_path)
                self.file_repo.delete(file_info.id)
        
        return task_deleted
    
    def create(self, **kwargs) -> TaskResponse:
        """åˆ›å»ºä»»åŠ¡å®ä½“ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰"""
        # è¿™é‡Œå®ç°åŒæ­¥çš„åˆ›å»ºé€»è¾‘ï¼Œä¸è¿‡ä¸å¸¸ç”¨
        raise NotImplementedError("è¯·ä½¿ç”¨ create_task æ–¹æ³•")
    
    def get_by_id(self, entity_id: int) -> Optional[TaskResponse]:
        """æ ¹æ®IDè·å–ä»»åŠ¡ï¼ˆæ€§èƒ½ä¼˜åŒ–ç‰ˆï¼‰"""
        print(f"ğŸš€ æŸ¥è¯¢ä»»åŠ¡ {entity_id}ï¼ˆä½¿ç”¨æ€§èƒ½ä¼˜åŒ–æŸ¥è¯¢ï¼‰...")
        start_time = time.time()
        
        # ä½¿ç”¨JOINé¢„åŠ è½½å…³è”æ•°æ®ï¼Œé¿å…N+1æŸ¥è¯¢
        task = self.task_repo.get_by_id_with_relations(entity_id)
        if not task:
            return None
        
        # å…³è”æ•°æ®å·²é¢„åŠ è½½ï¼Œæ— éœ€é¢å¤–æŸ¥è¯¢
        file_info = task.file_info
        ai_model = task.ai_model
        user_info = task.user
        
        issue_count = self.task_repo.count_issues(task.id)
        processed_issues = self.task_repo.count_processed_issues(task.id)
        
        result = TaskResponse.from_task_with_relations(task, file_info, ai_model, user_info, issue_count, processed_issues)
        
        total_time = time.time() - start_time
        print(f"âœ… ä»»åŠ¡æŸ¥è¯¢å®Œæˆï¼Œè€—æ—¶: {total_time*1000:.1f}ms")
        return result
    
    def update(self, entity_id: int, **kwargs) -> Optional[TaskResponse]:
        """æ›´æ–°ä»»åŠ¡"""
        updated_task = self.task_repo.update(entity_id, **kwargs)
        if not updated_task:
            return None
        
        file_info = self.file_repo.get_by_id(updated_task.file_id) if updated_task.file_id else None
        ai_model = self.model_repo.get_by_id(updated_task.model_id) if updated_task.model_id else None
        user_info = self.user_repo.get_by_id(updated_task.user_id) if updated_task.user_id else None
        issue_count = self.task_repo.count_issues(updated_task.id)
        processed_issues = self.task_repo.count_processed_issues(updated_task.id)
        return TaskResponse.from_task_with_relations(updated_task, file_info, ai_model, user_info, issue_count, processed_issues)