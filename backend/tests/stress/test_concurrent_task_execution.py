"""
é«˜å¹¶å‘ä»»åŠ¡æ‰§è¡Œæµ‹è¯•
æ¨¡æ‹ŸçœŸå®é«˜å¹¶å‘åœºæ™¯ä¸‹çš„ä»»åŠ¡åˆ›å»ºã€æ‰§è¡Œå’Œç®¡ç†
"""
import asyncio
import json
import pytest
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Any
import tempfile
from pathlib import Path

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
from app.services.auth import AuthService
from app.dto.user import UserCreate
from app.core.database import SessionLocal
from app.models.task import Task
from app.models.user import User


class TestConcurrentTaskExecution:
    """é«˜å¹¶å‘ä»»åŠ¡æ‰§è¡Œæµ‹è¯•ç±»"""
    
    @pytest.fixture(autouse=True)
    def setup_concurrent_users(self, client):
        """è®¾ç½®å¤šä¸ªå¹¶å‘ç”¨æˆ·"""
        self.concurrent_users = []
        
        # åˆ›å»º10ä¸ªæµ‹è¯•ç”¨æˆ·ç”¨äºå¹¶å‘æµ‹è¯•
        for i in range(10):
            # é€šè¿‡APIåˆ›å»ºç”¨æˆ·å¹¶è·å–token
            auth_data = {"code": f"concurrent_user_{i}_auth_code"}
            response = client.post("/api/auth/thirdparty/login", json=auth_data)
            
            if response.status_code == 200:
                result = response.json()
                self.concurrent_users.append({
                    "user_id": result["user"]["id"],
                    "token": result["access_token"],
                    "headers": {"Authorization": f"Bearer {result['access_token']}"}
                })
        
        assert len(self.concurrent_users) >= 5, "è‡³å°‘éœ€è¦5ä¸ªç”¨æˆ·è¿›è¡Œå¹¶å‘æµ‹è¯•"
        
        yield
        
        # æ¸…ç†å·¥ä½œ
        self.concurrent_users.clear()
    
    def create_test_document(self, size_kb: int = 1) -> tuple:
        """
        åˆ›å»ºæµ‹è¯•æ–‡æ¡£
        
        Args:
            size_kb: æ–‡æ¡£å¤§å°ï¼ˆKBï¼‰
        
        Returns:
            (filename, content, content_type)
        """
        # åˆ›å»ºæŒ‡å®šå¤§å°çš„æµ‹è¯•æ–‡æ¡£
        base_content = "è¿™æ˜¯ä¸€ä¸ªç”¨äºé«˜å¹¶å‘æµ‹è¯•çš„æ–‡æ¡£å†…å®¹ã€‚" * 50  # çº¦1KB
        content = base_content * size_kb
        
        # æ·»åŠ ä¸€äº›ç»“æ„åŒ–å†…å®¹
        structured_content = f"""
# æµ‹è¯•æ–‡æ¡£æ ‡é¢˜

## ç¬¬ä¸€èŠ‚ï¼šä»‹ç»
{content}

## ç¬¬äºŒèŠ‚ï¼šè¯¦ç»†å†…å®¹
{content}

## ç¬¬ä¸‰èŠ‚ï¼šæ€»ç»“
è¿™æ˜¯æ–‡æ¡£çš„æ€»ç»“éƒ¨åˆ†ï¼ŒåŒ…å«äº†é‡è¦çš„ç»“è®ºå’Œå»ºè®®ã€‚

### 3.1 å­ç« èŠ‚
æ›´å¤šè¯¦ç»†ä¿¡æ¯å’Œåˆ†æå†…å®¹ã€‚

### 3.2 å»ºè®®
åŸºäºåˆ†æçš„å…·ä½“å»ºè®®å’Œè¡ŒåŠ¨è®¡åˆ’ã€‚
        """
        
        return ("concurrent_test.md", structured_content.encode('utf-8'), "text/markdown")
    
    @pytest.mark.stress
    def test_concurrent_task_creation(self, client):
        """æµ‹è¯•å¹¶å‘ä»»åŠ¡åˆ›å»º"""
        print(f"\nğŸš€ å¼€å§‹å¹¶å‘ä»»åŠ¡åˆ›å»ºæµ‹è¯• - {len(self.concurrent_users)}ä¸ªç”¨æˆ·")
        
        def create_task(user_info: Dict) -> Dict:
            """å•ä¸ªç”¨æˆ·åˆ›å»ºä»»åŠ¡"""
            start_time = time.time()
            
            try:
                # åˆ›å»ºæµ‹è¯•æ–‡æ¡£
                filename, content, content_type = self.create_test_document(size_kb=2)
                
                # é€šè¿‡APIåˆ›å»ºä»»åŠ¡
                response = client.post(
                    "/api/tasks/",
                    files={"file": (filename, content, content_type)},
                    data={"description": f"å¹¶å‘æµ‹è¯•ä»»åŠ¡ - ç”¨æˆ·{user_info['user_id']}"},
                    headers=user_info["headers"]
                )
                
                end_time = time.time()
                
                return {
                    "user_id": user_info["user_id"],
                    "status_code": response.status_code,
                    "response_time": end_time - start_time,
                    "success": response.status_code == 201,
                    "task_id": response.json().get("id") if response.status_code == 201 else None,
                    "error": response.text if response.status_code != 201 else None
                }
                
            except Exception as e:
                end_time = time.time()
                return {
                    "user_id": user_info["user_id"],
                    "status_code": 500,
                    "response_time": end_time - start_time,
                    "success": False,
                    "task_id": None,
                    "error": str(e)
                }
        
        # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œå¹¶å‘ä»»åŠ¡åˆ›å»º
        start_time = time.time()
        results = []
        
        with ThreadPoolExecutor(max_workers=len(self.concurrent_users)) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_user = {
                executor.submit(create_task, user): user 
                for user in self.concurrent_users
            }
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_user):
                result = future.result()
                results.append(result)
        
        total_time = time.time() - start_time
        
        # åˆ†æç»“æœ
        successful_tasks = [r for r in results if r["success"]]
        failed_tasks = [r for r in results if not r["success"]]
        
        avg_response_time = sum(r["response_time"] for r in results) / len(results)
        max_response_time = max(r["response_time"] for r in results)
        min_response_time = min(r["response_time"] for r in results)
        
        print(f"ğŸ“Š å¹¶å‘ä»»åŠ¡åˆ›å»ºæµ‹è¯•ç»“æœ:")
        print(f"   æ€»ç”¨æˆ·æ•°: {len(self.concurrent_users)}")
        print(f"   æˆåŠŸä»»åŠ¡: {len(successful_tasks)}")
        print(f"   å¤±è´¥ä»»åŠ¡: {len(failed_tasks)}")
        print(f"   æ€»è€—æ—¶: {total_time:.2f}ç§’")
        print(f"   å¹³å‡å“åº”æ—¶é—´: {avg_response_time:.2f}ç§’")
        print(f"   æœ€å¤§å“åº”æ—¶é—´: {max_response_time:.2f}ç§’")
        print(f"   æœ€å°å“åº”æ—¶é—´: {min_response_time:.2f}ç§’")
        print(f"   æˆåŠŸç‡: {len(successful_tasks)/len(results)*100:.1f}%")
        
        # æ–­è¨€ï¼šè‡³å°‘80%çš„ä»»åŠ¡åˆ›å»ºæˆåŠŸ
        assert len(successful_tasks) >= len(self.concurrent_users) * 0.8, \
            f"å¹¶å‘ä»»åŠ¡åˆ›å»ºæˆåŠŸç‡è¿‡ä½: {len(successful_tasks)}/{len(self.concurrent_users)}"
        
        # æ–­è¨€ï¼šå¹³å‡å“åº”æ—¶é—´ä¸è¶…è¿‡5ç§’
        assert avg_response_time <= 5.0, \
            f"å¹³å‡å“åº”æ—¶é—´è¿‡é•¿: {avg_response_time:.2f}ç§’"
        
        # ä¿å­˜æˆåŠŸçš„ä»»åŠ¡IDä¾›åç»­æµ‹è¯•ä½¿ç”¨
        self.created_task_ids = [r["task_id"] for r in successful_tasks if r["task_id"]]
    
    @pytest.mark.stress 
    def test_concurrent_task_execution(self, client):
        """æµ‹è¯•å¹¶å‘ä»»åŠ¡æ‰§è¡Œ"""
        print(f"\nâš¡ å¼€å§‹å¹¶å‘ä»»åŠ¡æ‰§è¡Œæµ‹è¯•")
        
        # å…ˆåˆ›å»ºä¸€äº›ä»»åŠ¡
        task_ids = []
        for i, user in enumerate(self.concurrent_users[:5]):  # åªç”¨å‰5ä¸ªç”¨æˆ·
            filename, content, content_type = self.create_test_document(size_kb=1)
            
            response = client.post(
                "/api/tasks/",
                files={"file": (filename, content, content_type)},
                data={"description": f"å¹¶å‘æ‰§è¡Œæµ‹è¯•ä»»åŠ¡ {i}"},
                headers=user["headers"]
            )
            
            if response.status_code == 201:
                task_ids.append(response.json()["id"])
        
        assert len(task_ids) >= 3, "éœ€è¦è‡³å°‘3ä¸ªä»»åŠ¡ç”¨äºå¹¶å‘æ‰§è¡Œæµ‹è¯•"
        
        def execute_task(task_id: int, user_info: Dict) -> Dict:
            """æ‰§è¡Œå•ä¸ªä»»åŠ¡"""
            start_time = time.time()
            
            try:
                # é€šè¿‡APIæ‰§è¡Œä»»åŠ¡
                response = client.post(
                    f"/api/tasks/{task_id}/retry",
                    headers=user_info["headers"]
                )
                
                end_time = time.time()
                
                return {
                    "task_id": task_id,
                    "user_id": user_info["user_id"],
                    "status_code": response.status_code,
                    "response_time": end_time - start_time,
                    "success": response.status_code == 200,
                    "error": response.text if response.status_code != 200 else None
                }
                
            except Exception as e:
                end_time = time.time()
                return {
                    "task_id": task_id,
                    "user_id": user_info["user_id"],
                    "status_code": 500,
                    "response_time": end_time - start_time,
                    "success": False,
                    "error": str(e)
                }
        
        # æ‰§è¡Œå¹¶å‘ä»»åŠ¡
        start_time = time.time()
        results = []
        
        with ThreadPoolExecutor(max_workers=len(task_ids)) as executor:
            # æ¯ä¸ªä»»åŠ¡åˆ†é…ç»™ä¸€ä¸ªç”¨æˆ·æ‰§è¡Œ
            future_to_task = {}
            for i, task_id in enumerate(task_ids):
                user = self.concurrent_users[i % len(self.concurrent_users)]
                future_to_task[executor.submit(execute_task, task_id, user)] = task_id
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_task):
                result = future.result()
                results.append(result)
        
        total_time = time.time() - start_time
        
        # åˆ†æç»“æœ
        successful_executions = [r for r in results if r["success"]]
        failed_executions = [r for r in results if not r["success"]]
        
        avg_response_time = sum(r["response_time"] for r in results) / len(results)
        
        print(f"ğŸ“Š å¹¶å‘ä»»åŠ¡æ‰§è¡Œæµ‹è¯•ç»“æœ:")
        print(f"   æ‰§è¡Œä»»åŠ¡æ•°: {len(task_ids)}")
        print(f"   æˆåŠŸæ‰§è¡Œ: {len(successful_executions)}")
        print(f"   æ‰§è¡Œå¤±è´¥: {len(failed_executions)}")
        print(f"   æ€»è€—æ—¶: {total_time:.2f}ç§’")
        print(f"   å¹³å‡å“åº”æ—¶é—´: {avg_response_time:.2f}ç§’")
        
        # æ–­è¨€ï¼šè‡³å°‘70%çš„ä»»åŠ¡æ‰§è¡ŒæˆåŠŸ
        assert len(successful_executions) >= len(task_ids) * 0.7, \
            f"å¹¶å‘ä»»åŠ¡æ‰§è¡ŒæˆåŠŸç‡è¿‡ä½: {len(successful_executions)}/{len(task_ids)}"
    
    @pytest.mark.stress
    def test_concurrent_task_status_checking(self, client):
        """æµ‹è¯•å¹¶å‘ä»»åŠ¡çŠ¶æ€æŸ¥è¯¢"""
        print(f"\nğŸ“Š å¼€å§‹å¹¶å‘ä»»åŠ¡çŠ¶æ€æŸ¥è¯¢æµ‹è¯•")
        
        # åˆ›å»ºä¸€äº›ä»»åŠ¡ç”¨äºçŠ¶æ€æŸ¥è¯¢
        task_ids = []
        for i, user in enumerate(self.concurrent_users[:3]):
            filename, content, content_type = self.create_test_document()
            
            response = client.post(
                "/api/tasks/",
                files={"file": (filename, content, content_type)},
                data={"description": f"çŠ¶æ€æŸ¥è¯¢æµ‹è¯•ä»»åŠ¡ {i}"},
                headers=user["headers"]
            )
            
            if response.status_code == 201:
                task_ids.append(response.json()["id"])
        
        assert len(task_ids) >= 2, "éœ€è¦è‡³å°‘2ä¸ªä»»åŠ¡ç”¨äºçŠ¶æ€æŸ¥è¯¢æµ‹è¯•"
        
        def check_task_status(task_id: int, user_info: Dict, check_count: int = 10) -> Dict:
            """æ£€æŸ¥ä»»åŠ¡çŠ¶æ€å¤šæ¬¡"""
            start_time = time.time()
            successful_checks = 0
            total_checks = 0
            
            try:
                for _ in range(check_count):
                    response = client.get(
                        f"/api/tasks/{task_id}",
                        headers=user_info["headers"]
                    )
                    
                    total_checks += 1
                    if response.status_code == 200:
                        successful_checks += 1
                    
                    # çŸ­æš‚å»¶è¿Ÿæ¨¡æ‹ŸçœŸå®æŸ¥è¯¢é—´éš”
                    time.sleep(0.1)
                
                end_time = time.time()
                
                return {
                    "task_id": task_id,
                    "user_id": user_info["user_id"],
                    "total_checks": total_checks,
                    "successful_checks": successful_checks,
                    "response_time": end_time - start_time,
                    "success_rate": successful_checks / total_checks if total_checks > 0 else 0
                }
                
            except Exception as e:
                end_time = time.time()
                return {
                    "task_id": task_id,
                    "user_id": user_info["user_id"],
                    "total_checks": total_checks,
                    "successful_checks": successful_checks,
                    "response_time": end_time - start_time,
                    "success_rate": 0,
                    "error": str(e)
                }
        
        # å¹¶å‘çŠ¶æ€æŸ¥è¯¢
        start_time = time.time()
        results = []
        
        with ThreadPoolExecutor(max_workers=len(task_ids) * 2) as executor:
            # æ¯ä¸ªä»»åŠ¡ç”±ä¸¤ä¸ªä¸åŒç”¨æˆ·åŒæ—¶æŸ¥è¯¢
            futures = []
            for task_id in task_ids:
                for user in self.concurrent_users[:2]:  # å‰ä¸¤ä¸ªç”¨æˆ·
                    future = executor.submit(check_task_status, task_id, user, 5)
                    futures.append(future)
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(futures):
                result = future.result()
                results.append(result)
        
        total_time = time.time() - start_time
        
        # åˆ†æç»“æœ
        total_checks = sum(r["total_checks"] for r in results)
        total_successful_checks = sum(r["successful_checks"] for r in results)
        avg_success_rate = sum(r["success_rate"] for r in results) / len(results)
        
        print(f"ğŸ“Š å¹¶å‘çŠ¶æ€æŸ¥è¯¢æµ‹è¯•ç»“æœ:")
        print(f"   å¹¶å‘æŸ¥è¯¢æ•°: {len(results)}")
        print(f"   æ€»æŸ¥è¯¢æ¬¡æ•°: {total_checks}")
        print(f"   æˆåŠŸæŸ¥è¯¢æ¬¡æ•°: {total_successful_checks}")
        print(f"   æ€»è€—æ—¶: {total_time:.2f}ç§’")
        print(f"   å¹³å‡æˆåŠŸç‡: {avg_success_rate*100:.1f}%")
        
        # æ–­è¨€ï¼šæˆåŠŸç‡è‡³å°‘90%
        assert avg_success_rate >= 0.9, \
            f"å¹¶å‘çŠ¶æ€æŸ¥è¯¢æˆåŠŸç‡è¿‡ä½: {avg_success_rate*100:.1f}%"
    
    @pytest.mark.stress
    def test_mixed_concurrent_operations(self, client):
        """æµ‹è¯•æ··åˆå¹¶å‘æ“ä½œï¼ˆåˆ›å»ºã€æ‰§è¡Œã€æŸ¥è¯¢ï¼‰"""
        print(f"\nğŸ”„ å¼€å§‹æ··åˆå¹¶å‘æ“ä½œæµ‹è¯•")
        
        results = {
            "create": [],
            "execute": [],
            "query": []
        }
        
        def create_tasks(user_info: Dict, count: int = 3) -> List[Dict]:
            """åˆ›å»ºå¤šä¸ªä»»åŠ¡"""
            task_results = []
            for i in range(count):
                try:
                    filename, content, content_type = self.create_test_document()
                    start_time = time.time()
                    
                    response = client.post(
                        "/api/tasks/",
                        files={"file": (filename, content, content_type)},
                        data={"description": f"æ··åˆæµ‹è¯•ä»»åŠ¡ {i}"},
                        headers=user_info["headers"]
                    )
                    
                    end_time = time.time()
                    
                    task_results.append({
                        "operation": "create",
                        "user_id": user_info["user_id"],
                        "success": response.status_code == 201,
                        "response_time": end_time - start_time,
                        "task_id": response.json().get("id") if response.status_code == 201 else None
                    })
                    
                except Exception as e:
                    task_results.append({
                        "operation": "create",
                        "user_id": user_info["user_id"],
                        "success": False,
                        "response_time": 0,
                        "error": str(e)
                    })
            
            return task_results
        
        def query_tasks(user_info: Dict, count: int = 5) -> List[Dict]:
            """æŸ¥è¯¢ä»»åŠ¡åˆ—è¡¨"""
            query_results = []
            for i in range(count):
                try:
                    start_time = time.time()
                    
                    response = client.get(
                        "/api/tasks/",
                        headers=user_info["headers"]
                    )
                    
                    end_time = time.time()
                    
                    query_results.append({
                        "operation": "query",
                        "user_id": user_info["user_id"],
                        "success": response.status_code == 200,
                        "response_time": end_time - start_time
                    })
                    
                    time.sleep(0.2)  # æŸ¥è¯¢é—´éš”
                    
                except Exception as e:
                    query_results.append({
                        "operation": "query", 
                        "user_id": user_info["user_id"],
                        "success": False,
                        "response_time": 0,
                        "error": str(e)
                    })
            
            return query_results
        
        # æ‰§è¡Œæ··åˆå¹¶å‘æ“ä½œ
        start_time = time.time()
        
        with ThreadPoolExecutor(max_workers=len(self.concurrent_users)) as executor:
            futures = []
            
            # ä¸€åŠç”¨æˆ·åˆ›å»ºä»»åŠ¡
            for user in self.concurrent_users[:len(self.concurrent_users)//2]:
                future = executor.submit(create_tasks, user, 2)
                futures.append(future)
            
            # å¦ä¸€åŠç”¨æˆ·æŸ¥è¯¢ä»»åŠ¡
            for user in self.concurrent_users[len(self.concurrent_users)//2:]:
                future = executor.submit(query_tasks, user, 3)
                futures.append(future)
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(futures):
                operation_results = future.result()
                for result in operation_results:
                    results[result["operation"]].append(result)
        
        total_time = time.time() - start_time
        
        # åˆ†ææ··åˆæ“ä½œç»“æœ
        for operation, operation_results in results.items():
            if operation_results:
                successful = [r for r in operation_results if r["success"]]
                avg_time = sum(r["response_time"] for r in operation_results) / len(operation_results)
                
                print(f"ğŸ“Š {operation.upper()}æ“ä½œç»“æœ:")
                print(f"   æ“ä½œæ¬¡æ•°: {len(operation_results)}")
                print(f"   æˆåŠŸæ¬¡æ•°: {len(successful)}")
                print(f"   æˆåŠŸç‡: {len(successful)/len(operation_results)*100:.1f}%")
                print(f"   å¹³å‡å“åº”æ—¶é—´: {avg_time:.2f}ç§’")
        
        print(f"ğŸ¯ æ··åˆæ“ä½œæ€»è€—æ—¶: {total_time:.2f}ç§’")
        
        # æ–­è¨€ï¼šå„ç±»æ“ä½œçš„æˆåŠŸç‡éƒ½ä¸ä½äº75%
        for operation, operation_results in results.items():
            if operation_results:
                successful = [r for r in operation_results if r["success"]]
                success_rate = len(successful) / len(operation_results)
                assert success_rate >= 0.75, \
                    f"{operation}æ“ä½œæˆåŠŸç‡è¿‡ä½: {success_rate*100:.1f}%"
    
    @pytest.mark.stress
    def test_database_connection_pool_under_load(self, client):
        """æµ‹è¯•è´Ÿè½½ä¸‹çš„æ•°æ®åº“è¿æ¥æ± æ€§èƒ½"""
        print(f"\nğŸ—„ï¸ å¼€å§‹æ•°æ®åº“è¿æ¥æ± è´Ÿè½½æµ‹è¯•")
        
        def db_intensive_operation(user_info: Dict, operation_id: int) -> Dict:
            """æ•°æ®åº“å¯†é›†å‹æ“ä½œ"""
            start_time = time.time()
            
            try:
                # æ‰§è¡Œä¸€ç³»åˆ—æ•°æ®åº“å¯†é›†å‹æ“ä½œ
                operations = []
                
                # 1. æŸ¥è¯¢ä»»åŠ¡åˆ—è¡¨
                response1 = client.get("/api/tasks/", headers=user_info["headers"])
                operations.append(("list_tasks", response1.status_code == 200))
                
                # 2. æŸ¥è¯¢ç”¨æˆ·ä¿¡æ¯
                response2 = client.get("/api/users/me", headers=user_info["headers"])
                operations.append(("get_user", response2.status_code == 200))
                
                # 3. æŸ¥è¯¢AIè¾“å‡ºï¼ˆå¦‚æœæœ‰ä»»åŠ¡çš„è¯ï¼‰
                if response1.status_code == 200:
                    tasks = response1.json()
                    if tasks:
                        task_id = tasks[0]["id"]
                        response3 = client.get(f"/api/ai-outputs/task/{task_id}", headers=user_info["headers"])
                        operations.append(("get_ai_outputs", response3.status_code == 200))
                
                end_time = time.time()
                
                successful_ops = [op for op in operations if op[1]]
                
                return {
                    "operation_id": operation_id,
                    "user_id": user_info["user_id"],
                    "total_operations": len(operations),
                    "successful_operations": len(successful_ops),
                    "response_time": end_time - start_time,
                    "success": len(successful_ops) == len(operations)
                }
                
            except Exception as e:
                end_time = time.time()
                return {
                    "operation_id": operation_id,
                    "user_id": user_info["user_id"],
                    "total_operations": 0,
                    "successful_operations": 0,
                    "response_time": end_time - start_time,
                    "success": False,
                    "error": str(e)
                }
        
        # é«˜å¼ºåº¦æ•°æ®åº“æ“ä½œ
        start_time = time.time()
        results = []
        
        with ThreadPoolExecutor(max_workers=len(self.concurrent_users) * 2) as executor:
            futures = []
            
            # æ¯ä¸ªç”¨æˆ·æ‰§è¡Œå¤šæ¬¡æ•°æ®åº“æ“ä½œ
            operation_id = 0
            for user in self.concurrent_users:
                for i in range(3):  # æ¯ç”¨æˆ·3æ¬¡æ“ä½œ
                    future = executor.submit(db_intensive_operation, user, operation_id)
                    futures.append(future)
                    operation_id += 1
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(futures):
                result = future.result()
                results.append(result)
        
        total_time = time.time() - start_time
        
        # åˆ†ææ•°æ®åº“è¿æ¥æ± æ€§èƒ½
        successful_operations = [r for r in results if r["success"]]
        total_db_operations = sum(r["total_operations"] for r in results)
        successful_db_operations = sum(r["successful_operations"] for r in results)
        
        avg_response_time = sum(r["response_time"] for r in results) / len(results)
        max_response_time = max(r["response_time"] for r in results)
        
        print(f"ğŸ“Š æ•°æ®åº“è¿æ¥æ± è´Ÿè½½æµ‹è¯•ç»“æœ:")
        print(f"   å¹¶å‘æ“ä½œç»„æ•°: {len(results)}")
        print(f"   æˆåŠŸæ“ä½œç»„: {len(successful_operations)}")
        print(f"   æ€»æ•°æ®åº“æ“ä½œæ•°: {total_db_operations}")
        print(f"   æˆåŠŸæ•°æ®åº“æ“ä½œæ•°: {successful_db_operations}")
        print(f"   æ“ä½œç»„æˆåŠŸç‡: {len(successful_operations)/len(results)*100:.1f}%")
        print(f"   æ•°æ®åº“æ“ä½œæˆåŠŸç‡: {successful_db_operations/total_db_operations*100:.1f}%")
        print(f"   å¹³å‡å“åº”æ—¶é—´: {avg_response_time:.2f}ç§’")
        print(f"   æœ€å¤§å“åº”æ—¶é—´: {max_response_time:.2f}ç§’")
        print(f"   æ€»è€—æ—¶: {total_time:.2f}ç§’")
        
        # æ–­è¨€ï¼šæ•°æ®åº“æ“ä½œæˆåŠŸç‡è‡³å°‘85%
        db_success_rate = successful_db_operations / total_db_operations if total_db_operations > 0 else 0
        assert db_success_rate >= 0.85, \
            f"æ•°æ®åº“æ“ä½œæˆåŠŸç‡è¿‡ä½: {db_success_rate*100:.1f}%"
        
        # æ–­è¨€ï¼šå¹³å‡å“åº”æ—¶é—´ä¸è¶…è¿‡3ç§’
        assert avg_response_time <= 3.0, \
            f"æ•°æ®åº“æ“ä½œå¹³å‡å“åº”æ—¶é—´è¿‡é•¿: {avg_response_time:.2f}ç§’"


if __name__ == "__main__":
    pytest.main([__file__, "-v", "-m", "stress"])